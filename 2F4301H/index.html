<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222" media="(prefers-color-scheme: light)"><meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0"><link rel="preconnect" href="https://fonts.loli.net" crossorigin><link rel="preconnect" href="https://lib.baomitu.com" crossorigin><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png"><link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Noto+Serif+SC:300,300italic,400,400italic,700,700italic%7CLato:300,300italic,400,400italic,700,700italic%7C'Noto+Sans':300,300italic,400,400italic,700,700italic%7Csans-serif:300,300italic,400,400italic,700,700italic%7C'Noto+Sans+SC':300,300italic,400,400italic,700,700italic%7CRoboto+Serif:300,300italic,400,400italic,700,700italic%7CSource+Code+Pro:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="https://lib.baomitu.com/font-awesome/6.2.0/css/all.min.css" integrity="sha256-AbA177XfpSnFEvgpYu1jMygiLabzPCJCRIBtR5jGc0k=" crossorigin="anonymous"><script class="next-config" data-name="main" type="application/json">{"hostname":"1nnoh.top","root":"/","images":"/images","scheme":"Mist","darkmode":"auto","version":"8.13.2","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"width":269},"copycode":{"enable":false,"style":"flat"},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":{"gitalk":{"order":-1}}},"stickytabs":false,"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script><link rel="stylesheet" href="/js/prism/prism.css"><meta name="description" content="0x00 Abstract Requests 是一个 Python 公认的，优秀的第三方网络爬虫库，可以自动爬取 HTML 页面，自动进行网络请求的提交。所以本次任务首先来了解，学习 Requests 库以及 HTTP 协议。另外，由于Requests 库与 HTTP 协议的方法是一一对应的，所以会穿插着学习，以便更容易理解。"><meta property="og:type" content="article"><meta property="og:title" content="爬虫与网络编程基础-Task02：HTTP 协议与 Requests"><meta property="og:url" content="https://1nnoh.top/2F4301H/index.html"><meta property="og:site_name" content="1nnoh&#39;s Blog"><meta property="og:description" content="0x00 Abstract Requests 是一个 Python 公认的，优秀的第三方网络爬虫库，可以自动爬取 HTML 页面，自动进行网络请求的提交。所以本次任务首先来了解，学习 Requests 库以及 HTTP 协议。另外，由于Requests 库与 HTTP 协议的方法是一一对应的，所以会穿插着学习，以便更容易理解。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200044542.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200100765.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200102154.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200150745.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203201707788.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200326757.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200336254.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200340659.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200347742.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200349208.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200351450.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200354523.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203201605217.png"><meta property="article:published_time" content="2022-03-20T08:59:18.000Z"><meta property="article:modified_time" content="2022-03-20T08:59:18.000Z"><meta property="article:author" content="1nnoh"><meta property="article:tag" content="Coggle 30 Days of ML"><meta property="article:tag" content="Spider"><meta property="article:tag" content="Network Programming"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200044542.png"><link rel="canonical" href="https://1nnoh.top/2F4301H/"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://1nnoh.top/2F4301H/","path":"2F4301H/","title":"爬虫与网络编程基础-Task02：HTTP 协议与 Requests"}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>爬虫与网络编程基础-Task02：HTTP 协议与 Requests | 1nnoh's Blog</title><script src="/js/third-party/analytics/baidu-analytics.js"></script><script async src="https://hm.baidu.com/hm.js?b20166297c5501f4ebb46c56425f8cb4"></script><script async defer data-website-id="" src=""></script><script defer data-domain="" src=""></script><link rel="stylesheet" href="/js/prism/prism.css"><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><p class="site-title">1nnoh's Blog</p><i class="logo-line"></i></a></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" maxlength="80" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close" role="button"><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class="search-result-icon"><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#x00-abstract"><span class="nav-text">0x00 Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#x01-%E5%88%9D%E6%8E%A2-requests-%E5%BA%93"><span class="nav-text">0x01 初探 Requests 库</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%89%E8%A3%85"><span class="nav-text">1. 安装</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#requests-%E5%BA%93%E7%9A%84%E4%B8%83%E4%B8%AA%E4%B8%BB%E8%A6%81%E6%96%B9%E6%B3%95"><span class="nav-text">2. Requests 库的七个主要方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#requests.get-%E6%96%B9%E6%B3%95"><span class="nav-text">requests.get() 方法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%88%AC%E5%8F%96%E7%BD%91%E9%A1%B5%E7%9A%84%E9%80%9A%E7%94%A8%E4%BB%A3%E7%A0%81%E6%A1%86%E6%9E%B6"><span class="nav-text">3. 爬取网页的通用代码框架</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#x02-%E5%AD%A6%E4%B9%A0-http-%E5%8D%8F%E8%AE%AE"><span class="nav-text">0x02 学习 HTTP 协议</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#http-%E5%8D%8F%E8%AE%AE%E7%AE%80%E4%BB%8B"><span class="nav-text">HTTP 协议简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#http-%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="nav-text">HTTP 工作原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#url"><span class="nav-text">URL</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#http-%E5%8D%8F%E8%AE%AE%E5%AF%B9%E8%B5%84%E6%BA%90%E7%9A%84%E6%93%8D%E4%BD%9C"><span class="nav-text">HTTP 协议对资源的操作</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#x03-%E5%86%8D%E6%8E%A2-requests-%E5%BA%93"><span class="nav-text">0x03 再探 Requests 库</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#requests-%E5%BA%93%E4%B8%AD%E7%9A%84%E5%85%B6%E4%BB%96%E6%96%B9%E6%B3%95"><span class="nav-text">Requests 库中的其他方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#request.head-%E6%96%B9%E6%B3%95"><span class="nav-text">request.head() 方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#requests.post-%E6%96%B9%E6%B3%95"><span class="nav-text">requests.post () 方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#requests.put-%E6%96%B9%E6%B3%95"><span class="nav-text">requests.put() 方法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#requests-%E5%BA%93%E7%9A%84%E5%9F%BA%E7%A1%80%E6%96%B9%E6%B3%95"><span class="nav-text">Requests 库的基础方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#requests.-request-%E6%96%B9%E6%B3%95"><span class="nav-text">requests. request () 方法</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#x04-requests-%E5%AE%9E%E6%88%98"><span class="nav-text">0x04 Requests 实战</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#case-1.-%E4%BA%AC%E4%B8%9C%E5%95%86%E5%93%81%E9%A1%B5%E9%9D%A2%E7%9A%84%E7%88%AC%E5%8F%96"><span class="nav-text">Case 1. 京东商品页面的爬取</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#case-2.-%E7%99%BE%E5%BA%A6%E6%90%9C%E7%B4%A2%E7%BB%93%E6%9E%9C%E7%88%AC%E5%8F%96"><span class="nav-text">Case 2. 百度搜索结果爬取</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#case-3.-%E7%BD%91%E7%BB%9C%E5%9B%BE%E7%89%87%E7%9A%84%E7%88%AC%E5%8F%96%E5%92%8C%E5%AD%98%E5%82%A8"><span class="nav-text">Case 3. 网络图片的爬取和存储</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#references"><span class="nav-text">References</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="1nnoh" src="/images/avatar.jpg"><p class="site-author-name" itemprop="name">1nnoh</p><div class="site-description" itemprop="description">如常.</div></div><div class="site-state-wrap site-overview-item animated"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">19</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">8</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">10</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author site-overview-item animated"><span class="links-of-author-item"><a href="https://github.com/1nnoh" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;1nnoh" rel="noopener external nofollow noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:jhhou.cn@gmail.com" title="E-Mail → mailto:jhhou.cn@gmail.com" rel="noopener external nofollow noreferrer" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a></span></div><div class="cc-license site-overview-item animated" itemprop="license"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener external nofollow noreferrer" target="_blank"><img src="https://lib.baomitu.com/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a></div></div></div></div></aside></div><div class="main-inner post posts-expand"><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://1nnoh.top/2F4301H/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="1nnoh"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="1nnoh's Blog"><meta itemprop="description" content="如常."></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="爬虫与网络编程基础-Task02：HTTP 协议与 Requests | 1nnoh's Blog"><meta itemprop="description" content=""></span><header class="post-header"><h1 class="post-title" itemprop="name headline">爬虫与网络编程基础-Task02：HTTP 协议与 Requests</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2022-03-20 16:59:18" itemprop="dateCreated datePublished" datetime="2022-03-20T16:59:18+08:00">2022-03-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E7%88%AC%E8%99%AB%E4%B8%8E%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/" itemprop="url" rel="index"><span itemprop="name">爬虫与网络编程基础</span></a> </span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv"><span class="post-meta-item-icon"><i class="far fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span id="busuanzi_value_page_pv"></span> </span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>5.5k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>25 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><h2 id="x00-abstract">0x00 Abstract</h2><p>Requests 是一个 Python 公认的，优秀的第三方网络爬虫库，可以自动爬取 HTML 页面，自动进行网络请求的提交。所以本次任务首先来了解，学习 Requests 库以及 HTTP 协议。另外，由于Requests 库与 HTTP 协议的方法是一一对应的，所以会穿插着学习，以便更容易理解。</p><span id="more"></span><h2 id="x01-初探-requests-库">0x01 初探 Requests 库</h2><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://docs.python-requests.org/zh_CN/latest/">Requests: 让 HTTP 服务人类 — Requests 2.18.1 文档</a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://pypi.org/project/requests/">requests · PyPI</a></p><h3 id="安装">1. 安装</h3><p>安装 <code>requests</code>。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">pip install requests<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="requests-库的七个主要方法">2. Requests 库的七个主要方法</h3><table><colgroup><col style="width:25%"><col style="width:74%"></colgroup><thead><tr class="header"><th>方法</th><th>说明</th></tr></thead><tbody><tr class="odd"><td>requests.request()</td><td>构造一个请求，支持以下各方法的基础方法</td></tr><tr class="even"><td>requests.get()</td><td>获取 HTML 网页的主要方法，对应于 HTTP 的 GET</td></tr><tr class="odd"><td>requests.head()</td><td>获取 HTML 网页头信息的方法，对应于 HTTP 的 HEAD</td></tr><tr class="even"><td>requests.post()</td><td>向 HTML 网页提交 POST 请求的方法，对应于 HTTP 的 POST</td></tr><tr class="odd"><td>requests.put()</td><td>向 HTML 网页提交 PUT 请求的方法，对应于 HTTP 的 PUT</td></tr><tr class="even"><td>requests.patch()</td><td>向 HTML 网页提交局部修改请求，对应于 HTTP 的 PATCH</td></tr><tr class="odd"><td>requests.delete()</td><td>向 HTML 页面提交删除请求，对应于 HTTP 的 DELETE</td></tr></tbody></table><p>先来动动手：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import requests
r &#x3D; requests.get(&quot;http:&#x2F;&#x2F;www.baidu.com&quot;) # GET
r.status_code # 检测请求状态码<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><blockquote><p>200</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">r.encoding &#x3D; &#39;utf-8&#39; # 修改内容编码
r.text[:500] # 查看响应内容的字符串<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><blockquote><p><code>'&lt;!DOCTYPE html&gt;\r\n&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv=content-type content=text/html;charset=utf-8&gt;&lt;meta http-equiv=X-UA-Compatible content=IE=Edge&gt;&lt;meta content=always name=referrer&gt;&lt;link rel=stylesheet type=text/css href=http://s1.bdstatic.com/r/www/cache/bdorz/baidu.min.css&gt;&lt;title&gt;百度一下，你就知道&lt;/title&gt;&lt;/head&gt; &lt;body link=#0000cc&gt; &lt;div id=wrapper&gt; &lt;div id=head&gt; &lt;div class=head_wrapper&gt; &lt;div class=s_form&gt; &lt;div class=s_form_wrapper&gt; &lt;div id=lg&gt; &lt;img hidefocus=true src=//www.baidu.com/img/bd_'</code></p></blockquote><p>下面仅先介绍最常使用的 <code>requests.get()</code> 方法，其余的方法待学习了 HTTP 协议之后，再对照着理解。</p><h4 id="requests.get-方法">requests.get() 方法</h4><p><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200044542.png"></p><p>具体参数：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">r &#x3D; requests.get(url, params, **kwargs)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li><code>url</code> ：拟获取页面的 URL 链接。</li><li><code>params</code> ：URL 中的额外参数，字典或者字节流格式，可选。</li><li><code>**kwargs</code> : 12 个控制访问的参数</li></ul><p>通过 <code>requests.get()</code> 方法返回得到的 Response 对象具有以下属性：</p><table><colgroup><col style="width:28%"><col style="width:71%"></colgroup><thead><tr class="header"><th>属性</th><th>说明</th></tr></thead><tbody><tr class="odd"><td>r.status_code</td><td>HTTP 请求的返回状态，若为 200 则表示请求成功</td></tr><tr class="even"><td>r.text</td><td>HTTP 响应内容的字符串形式，即，url 对应的页面内容</td></tr><tr class="odd"><td>r.encoding</td><td>从 HTTP header 中猜测的相应内容编码方式</td></tr><tr class="even"><td>r.apparent_encoding</td><td>从内容中分析出的响应内容编码方式（备选编码方式）</td></tr><tr class="odd"><td>r.content</td><td>HTTP 响应内容的二进制形式</td></tr></tbody></table><p>这五个属性是最常使用的五个属性。 <code>r.status_code</code> 获得的状态码，只有返回 200 表示请求成功，其他则为失败，如 404。 <img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200100765.png" alt="|600"></p><p>使用 <code>requests.get()</code> 方法获取信息的基本流程： <img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200102154.png" alt="|500"></p><p><strong>Case 通过 get 获取网页信息</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import requests
r &#x3D; requests.get(&quot;http:&#x2F;&#x2F;www.baidu.com&quot;)
r.status_code # 返回 200，确认响应成功
r.text[-300:] # 查看响应内容<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p><code>'out Baidu&lt;/a&gt; &lt;/p&gt; &lt;p id=cp&gt;&amp;copy;2017&amp;nbsp;Baidu&amp;nbsp;&lt;a href=http://www.baidu.com/duty/&gt;ä½¿ç\x94¨ç\x99¾åº¦å\x89\x8då¿\x85è¯»&lt;/a&gt;&amp;nbsp; &lt;a href=http://jianyi.baidu.com/ class=cp-feedback&gt;æ\x84\x8fè§\x81å\x8f\x8dé¦\x88&lt;/a&gt;&amp;nbsp;äº¬ICPè¯\x81030173å\x8f·&amp;nbsp; &lt;img src=//www.baidu.com/img/gs.gif&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt;\r\n'</code></p></blockquote><p>可以发现，返回的内容中有很多乱码。那么来看一下内容的编码方式。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">r.encoding # 从 header 猜测编码<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>'ISO-8859-1'</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">r.apparent_encoding # 备选编码<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>'utf-8'</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">r.encoding &#x3D; &#39;utf-8&#39; # 使用备选编码替换当前编码方式
r.text[-300:] # 再次查看响应内容<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><blockquote><p><code>' href=http://ir.baidu.com&gt;About Baidu&lt;/a&gt; &lt;/p&gt; &lt;p id=cp&gt;&amp;copy;2017&amp;nbsp;Baidu&amp;nbsp;&lt;a href=http://www.baidu.com/duty/&gt;使用百度前必读&lt;/a&gt;&amp;nbsp; &lt;a href=http://jianyi.baidu.com/ class=cp-feedback&gt;意见反馈&lt;/a&gt;&amp;nbsp;京 ICP 证 030173 号&amp;nbsp; &lt;img src=//www.baidu.com/img/gs.gif&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt;\r\n'</code></p></blockquote><p>经过替换编码方式，原来的一些乱码变成了中文。变得具有可读性了。为什么会这样？那就需要理解 Response 的编码。</p><table><colgroup><col style="width:29%"><col style="width:70%"></colgroup><thead><tr class="header"><th>属性</th><th>说明</th></tr></thead><tbody><tr class="odd"><td>r.encoding</td><td>从 HTTP header 中猜测的相应内容编码方式</td></tr><tr class="even"><td>r.apparent_encoding</td><td>从内容中分析出的响应内容编码方式（备选编码方式）</td></tr></tbody></table><p><code>r.encoding</code>：如果 header 中不存在 charset 字段，则默认编码为 ISO-8859-1。 就是当我们刚刚访问百度的时候，默认的编码。但这个编码并不能解析中文，所以查看内容时，会出现乱码。</p><p><code>r.apparent_encoding</code>：根据网页内容分析出的编码方式。 为了避免上述情况，<code>Requests</code> 库还提供了另一种备选编码方案，从 HTTP 的内容部分（而不是头部份），去分析内容可能的编码形式。严格来说 <code>r.apparent_encoding</code> 比 <code>r.encoding</code> 更加准确，因为前者是实实在在去分析内容，找到可能的编码；而后者只是从 header 的相关字段中提取编码。所以当后者不能正确解码时，需要使用前者——备用编码，来解析返回的信息。这也是为什么示例中替换编码方式后，即可正确解析出中文的原因。</p><h3 id="爬取网页的通用代码框架">3. 爬取网页的通用代码框架</h3><p>注意 <code>Requests</code> 库有时会产生异常，比如网络连接错误、<code>HTTP</code> 错误异常、重定向异常、请求 <code>URL</code> 超时异常等等。所以我们需要判断 <code>r.status_codes</code> 是否为 200，在这里我们怎么样去捕捉异常呢？</p><p>这里我们可以利用 <code>r.raise_for_status()</code> 语句去捕捉异常，该语句在方法内部判断 <code>r.status_code</code> 是否等于 200，如果不等于，则抛出异常。</p><p>于是在这里我们有一个爬取网页的通用代码框架：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">try:
    r &#x3D; requests.get(url, timeout&#x3D;30) # 请求超时时间为 30 秒
    r.raise_for_status() # 如果状态不是 200，则引发 HTTPError 异常
    r.encoding &#x3D; r.apparent_encoding # 配置编码
    return r.text 
except:
    return &quot;产生异常&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200150745.png"></p><p>可见当 <code>url</code> 链接没有协议，产生错误时，抛出了异常。</p><p>通过这种框架，可以使我们的爬虫方法更加可靠，稳定。</p><h2 id="x02-学习-http-协议">0x02 学习 HTTP 协议</h2><p>为了更好的理解 Requests 库中的这些方法，我们需要学习并了解 HTTP 协议。</p><h3 id="http-协议简介">HTTP 协议简介</h3><p>HTTP，<strong>H</strong>yper<strong>T</strong>ext <strong>T</strong>ransfer <strong>P</strong>rotocol，超文本传输协议。</p><p>HTTP 是万维网的数据通信的基础。</p><p>HTTP 是一种基于“请求与响应”模式的，无状态的应用层协议。</p><ul><li>“请求与响应”：用户发起请求，服务器做相关响应。</li><li>无状态：第一次请求与第二次请求之间，没有关联。并且对于发送过的请求或响应都不进行保存。</li><li>应用层协议：该协议基于 TCP 协议。</li></ul><h3 id="http-工作原理">HTTP 工作原理</h3><p>HTTP 协议定义 Web 客户端如何从 Web 服务器请求 Web 页面，以及服务器如何把 Web 页面传送给客户端。HTTP 协议采用了请求/响应模型。客户端向服务器发送一个请求报文，请求报文包含请求的方法、URL、协议版本、请求头部和请求数据。服务器以一个状态行作为响应，响应的内容包括协议的版本、成功或者错误代码、服务器信息、响应头部和响应数据。</p><p>以下是 HTTP 请求/响应的步骤：</p><ol type="1"><li>客户端连接到 Web 服务器。</li><li>发送 HTTP 请求。</li><li>服务器接受请求并返回 HTTP 响应。</li><li>释放连接 TCP 连接。</li><li>客户端浏览器解析 HTML 内容。</li></ol><p>在浏览器地址栏键入 URL，按下回车之后会经历以下流程：</p><ol type="1"><li>浏览器向 DNS 服务器请求解析该 URL 中的域名所对应的 IP 地址。</li><li>解析出 IP 地址后，根据该 IP 地址和默认端口 80，和服务器建立 TCP 连接。</li><li>浏览器发出读取文件 (URL 中域名后面部分对应的文件) 的 HTTP 请求，该请求报文作为 TCP 三次握手的第三个报文的数据发送给服务器。</li><li>服务器对浏览器请求作出响应，并把对应的 HTML 文本发送给浏览器。</li><li>释放 TCP 连接。</li><li>浏览器将该 HTML 文本并显示内容。</li></ol><h3 id="url">URL</h3><p>URL，Universal Resource Locator，<strong>统一资源定位符</strong>。</p><p>HTTP 协议采用 URL 作为定位网络资源的标识。</p><p>URL 遵守一种标准的语法，它由协议、域名、端口、路径名称、查询字符串、以及锚部分这六个部分构成，其中端口可以省略，查询字符串和锚部分为参数。具体语法规则如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">protocol:&#x2F;&#x2F;host: port&#x2F;pathname?query#fragment<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在上述语法规则中，<code>protocol</code> 表示协议，<code>host</code> 表示主机名（域名或 IP 地址），<code>port</code> 表示端口，<code>pathname</code> 表示路径名称，<code>query</code> 表示查询字符串，<code>fragment</code> 表示锚部分。<code>#</code> 代表网页中的一个位置，作为页面 <code>定位符</code> 出现在 URL 中。其右面的字符，就是该位置的 <code>标识符</code>（锚部分）。</p><p><strong>统一资源定位符</strong> 将从因特网获取信息的几种基本元素包含在一个简单的地址中：</p><ul><li>传输协议 - protocol<ul><li>如 http/https/ftp 等。</li></ul></li><li>服务器 - host<ul><li>通常为域名：因为 IP 地址不好记，因此用域名美化，可以理解为 IP 的别名。使用域名 -&gt; 通过 DNS 解析找到对应的 IP。</li><li>有时为 IP 地址：主机地址，每台电脑都有自己特定的标识，IPv4/IPv6。</li></ul></li><li>端口号 - port （可省略）：可以理解为窗口，交流的端口<ul><li>http：默认打开 80 端口</li><li>https：默认打开 443 端口</li></ul></li><li>路径 - path：访问主机分享文件的地址<ul><li>以 <code>/</code> 字符区别路径中的每一个目录名称</li><li>文件路径：用户直接访问主机分享的文件</li><li>路由：目前比较流行的形式（后端监听地址访问事件，返回特定的内容）</li></ul></li><li>查询参数 - query：帮助用户访问到特定的资源<ul><li>格式 <code>?name=value&amp;name=value...</code></li><li>GET 模式的表单参数，以 <code>?</code> 字符为起点，每个参数以 <code>&amp;</code> 隔开，再以 <code>=</code> 分开参数名称与资料，通常以 UTF8 的 URL 编码，避开字符冲突的问题。</li></ul></li><li>锚点 - fragment：<ul><li><code>#fragment</code> 锚点，又叫命名锚记，是文档中的一种标记，网页设计者可以用它和 URL“锚”在一起，其作用像一个迅速定位器一样，可快速将访问者带到指定位置。</li><li>HTTP 请求不包括 <code>#</code> ：<code>#</code> 是用来指导浏览器动作的，对服务器端完全无用。</li></ul></li></ul><p>典型的统一资源定位符看上去是这样的：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">http:&#x2F;&#x2F;zh.wikipedia.org:80&#x2F;w&#x2F;index.php?title&#x3D;Special:%E9%9A%8F%E6%9C%BA%E9%A1%B5%E9%9D%A2&amp;printable&#x3D;yes<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中：</p><ol type="1"><li><code>http</code> 是协议；</li><li><code>zh.wikipedia.org</code> 是服务器；</li><li><code>80</code> 是服务器上的网络端口号；</li><li><code>/w/index.php</code> 是路径；</li><li><code>?title=Special:%E9%9A%8F%E6%9C%BA%E9%A1%B5%E9%9D%A2&amp;printable=yes</code> 是查询参数。</li></ol><p>大多数网页浏览器不要求用户输入网页中 <code>http://</code> 的部分，因为绝大多数网页内容是超文本传输协议文件。同样，<code>80</code> 是超文本传输协议文件的常用端口号，因此一般也不必写明。一般来说用户只要键入统一资源定位符的一部分就可以了。<strong>这只是浏览器中可以省略，写爬虫的时候，URL 中的传输协议是不可以省略的。</strong></p><p><strong>总结</strong>：URL 是通过 HTTP 协议存取资源的 Internet 路径，一个 URL 对应一个数据资源。</p><h3 id="http-协议对资源的操作">HTTP 协议对资源的操作</h3><table><thead><tr class="header"><th>方法</th><th>说明</th></tr></thead><tbody><tr class="odd"><td>GET</td><td>请求获取 URL 位置的资源</td></tr><tr class="even"><td>HEAD</td><td>请求获取 URL 位置资源的响应消息报告，即获取该资源的头部信息</td></tr><tr class="odd"><td>POST</td><td>请求向 URL 位置的资源后附加新的数据</td></tr><tr class="even"><td>PUT</td><td>请求向 URL 位置存储一个资源，覆盖原 URL 位置的资源</td></tr><tr class="odd"><td>PATCH</td><td>请求局部更新 URL 位置的资源，即改变该处资源的部分内容</td></tr><tr class="even"><td>DELETE</td><td>请求删除 URL 位置存储的资源</td></tr></tbody></table><p><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203201707788.png"></p><p><strong>GET 与 POST 的区别</strong>：</p><ul><li>原理区别：GET 请求获取资源，不会产生动作；POST 可能会修改服务器上的资源。因此 POST 用于修改和写入数据，GET 一般用于搜索排序和筛选之类的操作，目的是资源的获取，读取数据。</li><li>参数位置区别：GET 把参数包含在 URL 中，POST 通过 Request body 传递参数。所以 POST 可以发送的数据更大，GET 有 URL 长度限制；POST 能发送更多的数据类型（GET 只能发送 ASCII 字符）。</li><li>POST 更加安全：不会作为 URL 的一部分，不会被缓存、保存在服务器日志、以及浏览器浏览记录中。</li><li>POST 比 GET 慢：POST 在真正接收数据之前会先将请求头发送给服务器进行确认，然后才真正发送数据。<ul><li>浏览器请求 TCP 连接（第一次握手）</li><li>服务器答应进行 TCP 连接（第二次握手）</li><li>浏览器确认，并发送 POST 请求头（第三次握手，这个报文比较小，所以 HTTP 会在此时进行第一次数据发送）</li><li>服务器返回 100 Continue 响应</li><li>浏览器发送数据</li><li>服务器返回 200 OK 响应</li></ul></li></ul><p><strong>PATCH 与 PUT 的区别</strong>： 假设 URL 位置有一组数据 UserInfo，包括 UserID，UserName 等 20 个字段。 需求：修改 UserName，其他不变。</p><ul><li>采用 PATCH，仅向 URL 提交 UserName 的局部更新请求。</li><li>采用 PUT，必须将所有 20 个字段一并提交到 URL，未提交的字段将被删除。</li></ul><p>因此 PATCH 的最主要好处是：节省网络带宽。</p><h2 id="x03-再探-requests-库">0x03 再探 Requests 库</h2><p>HTTP 协议方法与 Requests 库方法是一一对应的。因此有了对 HTTP 协议方法的理解之后，我们再来学习 Requests 库中的其他方法。</p><h3 id="requests-库中的其他方法">Requests 库中的其他方法</h3><h4 id="request.head-方法">request.head() 方法</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">&gt;&gt;&gt; r &#x3D; requests.head(&quot;http:&#x2F;&#x2F;httpbin.org&#x2F;get&quot;)
&gt;&gt;&gt; r.headers
&#123;&#39;Date&#39;: &#39;Sat, 19 Mar 2022 18:27:08 GMT&#39;, &#39;Content-Type&#39;: &#39;application&#x2F;json&#39;, &#39;Content-Length&#39;: &#39;307&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;, &#39;Server&#39;: &#39;gunicorn&#x2F;19.9.0&#39;, &#39;Access-Control-Allow-Origin&#39;: &#39;*&#39;, &#39;Access-Control-Allow-Credentials&#39;: &#39;true&#39;&#125;
&gt;&gt;&gt; r.text
&#39;&#39;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到 <code>r.text</code> 为空，因此通过 <code>head()</code> 方法可以用很少的网络流量，来获得网页的概括信息。</p><h4 id="requests.post-方法">requests.post () 方法</h4><ol type="1"><li>向 URL POST 一个字典，自动编码为 form。</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python">&gt;&gt;&gt; payload &#x3D; &#123;&quot;key1&quot;: &quot;value1&quot;,&quot;key2&quot;: &quot;value2&quot;&#125;
&gt;&gt;&gt; r &#x3D; requests.post(&quot;http:&#x2F;&#x2F;httpbin.org&#x2F;post&quot;, data &#x3D; payload)
&gt;&gt;&gt; print(r.text)
&#123; ...
  &quot;form&quot;: &#123;
    &quot;key1&quot;: &quot;value1&quot;, 
    &quot;key2&quot;: &quot;value2&quot;
  &#125;, 
...
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可见，当向 URL POST 一个字典或者键值对的时候，会默认存储在表单 form 的字段下。</p><ol start="2" type="1"><li>向 URL POST 一个字符串，自动编码为 data。</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python">&gt;&gt;&gt;r &#x3D; requests.post(&quot;http:&#x2F;&#x2F;httpbin.org&#x2F;post&quot;, data &#x3D; &#39;juanbudongle&#39;)
&gt;&gt;&gt;print(r.text)
&#123; ...
  &quot;data&quot;: &quot;juanbudongle&quot;,
  &quot;files&quot;: &#123;&#125;,
  &quot;form&quot;: &#123;&#125;
&#125;
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="requests.put-方法">requests.put() 方法</h4><p>与 POST 类似，只是会覆盖原 URL 位置的资源</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">&gt;&gt;&gt; payload &#x3D; &#123;&quot;key1&quot;: &quot;value1&quot;,&quot;key2&quot;: &quot;value2&quot;&#125;
&gt;&gt;&gt; r &#x3D; requests.put(&quot;http:&#x2F;&#x2F;httpbin.org&#x2F;post&quot;, data &#x3D; payload)
&gt;&gt;&gt; print(r.text)
&#123; ...
  &quot;form&quot;: &#123;
    &quot;key1&quot;: &quot;value1&quot;, 
    &quot;key2&quot;: &quot;value2&quot;
  &#125;, 
...
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>requests.post ()</code> 与 <code>requests.put()</code> 类似，上节末尾已经分析过两种方法的区别。</p><h3 id="requests-库的基础方法">Requests 库的基础方法</h3><p><code>requests.request()</code> 是 Requests 库所有方法的基础方法，因此将其单列出来。或者说，库中其他方法的实现，都是基于 <code>requests.request()</code> 方法。</p><h4 id="requests.-request-方法">requests. request () 方法</h4><p><code>requests.request(method, url, **kwargs)</code></p><ul><li><code>method</code> ：请求方式，对应 GET/PUT/POST 等 7 种。</li><li><code>url</code> ：拟获取页面的 URL 链接。</li><li><code>**kwargs</code> : 控制访问的参数，共 13 个。</li></ul><p>7 种请求方式如下： <img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200326757.png" alt="|500"></p><p><code>**kwargs</code> 控制访问的参数，一共有 13 个，均为可选项，下面依次讲解：</p><ul><li>params：字典或字节序列，作为参数增加到 <code>url</code> 中。 <img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200336254.png" alt="|700"></li><li>data：字典，字节序或文件对象，作为 Request 的内容。 <img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200340659.png" alt="|700"> 提交的键值对不直接存在 <code>url</code> 链接中，而是放在 Request 规定的存储位置。参考 <a href="#requests%20post%20方法">requests post 方法</a> 。</li><li>json：json 格式的数据，作为 Request 的内容。 <img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200347742.png" alt="|700"></li><li>headers：字典，HTTP 定制头。 <img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200349208.png"></li><li>cookies：字典或 CookieJar，Request 中的 cookie。</li><li>auth：元组，支持 HTTP 认证功能。</li><li>files：字典类型，传输文件。 <img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200351450.png" alt="|700"></li><li>timeout: 设定超时时间，秒为单位。</li><li>proxies：字典类型，设定访问代理服务器，可以增加登录认证。 <img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203200354523.png"> 使用这个字段，可以有效隐藏用户爬取网页的源的 IP 地址信息，有效防止对爬虫的逆追踪。</li><li>allow_redirects: True/False，默认为 True，重定向开关。</li><li>stream：True/False，默认为 True，获取内容立即下载开关。</li><li>verify：True/False，默认为 True，认证 SSL 证书开关。</li><li>cert： 本地 SSL 证书路径。</li></ul><h2 id="x04-requests-实战">0x04 Requests 实战</h2><h3 id="case-1.-京东商品页面的爬取">Case 1. 京东商品页面的爬取</h3><p>对这个 <a target="_blank" rel="noopener external nofollow noreferrer" href="https://item.jd.com/100029199502.html">手机商品页面</a> 进行爬取。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">&gt;&gt;&gt; import requests
&gt;&gt;&gt; url &#x3D; &#39;https:&#x2F;&#x2F;item.jd.com&#x2F;100029199502.html&#39;
&gt;&gt;&gt; r &#x3D; requests.get(url)
&gt;&gt;&gt; r.status_code
200
&gt;&gt;&gt; r.encoding
&#39;UTF-8&#39;
&gt;&gt;&gt; r.text
&#123;&#39;Date&#39;: &#39;Sat, 19 Mar 2022 18:27:08 GMT&#39;, &#39;Content-Type&#39;: &#39;application&#x2F;json&#39;, &#39;Content-Length&#39;: &#39;307&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;, &#39;Server&#39;: &#39;gunicorn&#x2F;19.9.0&#39;, &#39;Access-Control-Allow-Origin&#39;: &#39;*&#39;, &#39;Access-Control-Allow-Credentials&#39;: &#39;true&#39;&#125;
&gt;&gt;&gt; r.text
&quot;&lt;script&gt;window.location.href&#x3D;&#39;https:&#x2F;&#x2F;passport.jd.com&#x2F;new&#x2F;login.aspx?ReturnUrl&#x3D;http%3A%2F%2Fitem.jd.com%2F100029199502.html&#39;&lt;&#x2F;script&gt;&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以上都是基本流程操作，我们发现返回的信息并不是商品页面。如果将这个返回的 URL 在浏览器中打开，会呈现一个登录页面。或者说京东阻止了这个爬虫，把我们重定向到了登陆页面。因为我们即使不登陆，在浏览器上还是可以访问的。</p><p>一般网页限制爬虫的方式有两种，一种是通过 Robots 协议，告知爬虫，哪些资源可以访问，哪些不可以；另一种是根据 HTTP 的 Header 中的 user-agent 来检测，判断这个 HTTP 访问是不是由爬虫发起的，对于爬虫的请求，网站是可以选择拒绝的。</p><p>由于 <code>Requests</code> 库返回的 <code>Response</code> 对象（也就是 <code>requests.get()</code> 返回的 <code>r</code> ），包含发出的 <code>request</code> 请求，因此我们可以查看之前对京东发出的请求到底是什么内容。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">&gt;&gt;&gt; r.request.headers  # 查看发出的头信息
&#123;&#39;User-Agent&#39;: &#39;python-requests&#x2F;2.27.1&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Accept&#39;: &#39;*&#x2F;*&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;&#125;
# 可以发现，这里标明了我们是使用 &#39;python-requests&#x2F;2.27.1&#39; 发出的请求
# 也就是说我们的爬虫诚实地告诉了服务器，这个请求是由一个爬虫产生的
# 因此，如果京东进行来源审查，并且不支持这种访问的时候，我们的访问会被拒绝
# 那么此时，我们就应该模拟浏览器来进行爬虫请求
&gt;&gt;&gt; kv &#x3D; &#123;&#39;user-agent&#39;: &#39;Mozilla&#x2F;7.0&#39;&#125;  # 构造一个键值对，指定 user-agent
&gt;&gt;&gt; url &#x3D; &#39;https:&#x2F;&#x2F;item.jd.com&#x2F;100029199502.html&#39;
&gt;&gt;&gt; r &#x3D; requests.get(url, headers &#x3D; kv)  # 修改 HTTP 头中的 user-agent
&gt;&gt;&gt; r.status_code
200
&gt;&gt;&gt; r.request.headers  # 查看发出请求的头信息
&#123;&#39;user-agent&#39;: &#39;Mozilla&#x2F;7.0&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Accept&#39;: &#39;*&#x2F;*&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;&#125;
# 可以看到 user-agent 已经修改为我们键值对中的内容
&gt;&gt;&gt; r.text[:600]  # 查看返回内容
&#39;&lt;!DOCTYPE HTML&gt;\n&lt;html lang&#x3D;&quot;zh-CN&quot;&gt;\n&lt;head&gt;\n    &lt;!-- shouji --&gt;\n    &lt;meta http-equiv&#x3D;&quot;Content-Type&quot; content&#x3D;&quot;text&#x2F;html; charset&#x3D;utf-8&quot; &#x2F;&gt;\n    &lt;title&gt;【华为Mate X2】华为 HUAWEI Mate X2 5G全网通12GB+512GB墨黑素皮款 典藏版 麒麟芯片 超感知徕卡四摄 折叠屏 华为手机【行情 报价 价格 评测】-京东&lt;&#x2F;title&gt;\n    &lt;meta name&#x3D;&quot;keywords&quot; content&#x3D;&quot;HUAWEIMate X2,华为Mate X2,华为Mate X2报价,HUAWEIMate X2报价&quot;&#x2F;&gt;\n    &lt;meta name&#x3D;&quot;description&quot; content&#x3D;&quot;【华为Mate X2】京东JD.COM提供华为Mate X2正品行货，并包括HUAWEIMate X2网购指南，以及华为Mate X2图片、Mate X2参数、Mate X2评论、Mate X2心得、Mate X2技巧等信息，网购华为Mate X2上京东,放心又轻松&quot; &#x2F;&gt;\n    &lt;meta name&#x3D;&quot;format-detection&quot; content&#x3D;&quot;telephone&#x3D;no&quot;&gt;\n    &lt;meta http-equiv&#x3D;&quot;mobile&#39;
# 正常返回商品页面<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以上是在 Python IDLE 中的测试，下面给出全代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import requests
url &#x3D; &#39;https:&#x2F;&#x2F;item.jd.com&#x2F;100029199502.html&#39;
try:
    kv &#x3D; &#123;&#39;user-agent&#39;: &#39;Mozilla&#x2F;7.0&#39;&#125;
    r &#x3D; requests.get(url, headers &#x3D; kv)
    r.raise_for_status()
    r.encoding &#x3D; r.apparent_encoding
    print(r.text[:1000])
except:
    print(&quot;Error&quot;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>总结：有的时候需要修改头信息 'user-agent'，模拟浏览器向服务器提交 HTTP 请求。</strong></p><h3 id="case-2.-百度搜索结果爬取">Case 2. 百度搜索结果爬取</h3><p>百度的搜索关键词接口： <code>https://www.baidu.com/s?wd=keyword</code></p><p>这里要注意的是，简单的给 HTTP 头信息进行修改是没用的，需要去找一个真实的 User-Agent 修改到头信息中。</p><p>在浏览器中按下 F12： <img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203201605217.png" alt="|800"></p><p>随便选取一个 GET 请求，复制请求标头里的用户代理 User-Agent 信息。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">&gt;&gt;&gt; agent &#x3D; &#123;&#39;user-agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64; rv:84.0) Gecko&#x2F;20100101 Firefox&#x2F;84.0&#39;&#125;
&gt;&gt;&gt; kv &#x3D; &#123;&#39;wd&#39;: &#39;Python&#39;&#125;
&gt;&gt;&gt; r &#x3D; requests.get (&#39; https:&#x2F;&#x2F;www.baidu.com&#x2F;s &#39;, params&#x3D;kv, headers&#x3D;agent)
&gt;&gt;&gt; r.request.url  # 查看发出的 HTTP 请求的 URL
&#39;https:&#x2F;&#x2F;www.baidu.com&#x2F;s?wd&#x3D;Python&#39;
# 可以看到，搜素关键词添加到了后面
&gt;&gt;&gt; r.request.headers
&#123;&#39;user-agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64; rv:84.0) Gecko&#x2F;20100101 Firefox&#x2F;84.0&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Accept&#39;: &#39;*&#x2F;*&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;&#125;
&gt;&gt;&gt; r.status_code
200
&gt;&gt;&gt; len(r.text)  # 查看返回内容的长度
786376
# 这就说明返回成功了
# 修改 User-Agent 不正确时，返回的长度只有 227，即代表被百度服务器阻止访问了<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>总结：在实际应用时，可能会涉及各种伪装技巧，反反爬也是要考虑的一方面。</strong></p><h3 id="case-3.-网络图片的爬取和存储">Case 3. 网络图片的爬取和存储</h3><p>在国家地理的网站上随便找 <a target="_blank" rel="noopener external nofollow noreferrer" href="http://www.ngchina.com.cn/news/detail?newsId=47344">一幅图</a>，通过查看网页源码找到这幅图的 URL。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">&gt;&gt;&gt; import requests
&gt;&gt;&gt; path &#x3D; &quot;city.jpg&quot;  # 给图片一个存储位置，存在当前目录下，命名为 city
&gt;&gt;&gt; url &#x3D; &#39;https:&#x2F;&#x2F;ngimages.oss-cn-beijing.aliyuncs.com&#x2F;2022&#x2F;03&#x2F;16&#x2F;fabe20d0-01cc-400d-ae07-8f56516a556a.jpg&#39;  # 源码中找到的图的 URL
&gt;&gt;&gt; r &#x3D; requests.get(url)
&gt;&gt;&gt; r.status_code
200  # 成功
&gt;&gt;&gt; with open(path, &#39;wb&#39;) as f:  # 将图片以二进制形式写入文件
	    f.write(r.content)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>完整代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">import requests
import os

url &#x3D; &#39;https:&#x2F;&#x2F;ngimages.oss-cn-beijing.aliyuncs.com&#x2F;2022&#x2F;03&#x2F;16&#x2F;fabe20d0-01cc-400d-ae07-8f56516a556a.jpg&#39;
root &#x3D; &quot;E:&#x2F;&#x2F;pics&#x2F;&#x2F;&quot;
path &#x3D; root + url.split(&#39;&#x2F;&#39;)[-1]  # .spilt 返回⼀个将字符串以 &#x2F; 划分的列表，取 [-1]，即最后一个（或者说倒数第一个），也就是 URL 中图片的名字
try:
    kv &#x3D; &#123;&#39;user-agent&#39;: &#39;Mozilla&#x2F;5.0&#39;&#125;
    if not os.path.exists(root):  # 如果根目录不存在，则新建根目录
        os.mkdir(root)
    if not os.path.exists(path):  # 如果文件不存在，则从网上爬取并存储
        r &#x3D; requests.get(url)
        with open(path, &#39;wb&#39;) as f:
            f.write(r.content)
            print(&quot;文件保存成功&quot;)
    else:
        print(&quot;文件保存成功&quot;)
except:
    print(&quot;爬取失败&quot;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>总结：在工程要求上，代码的可靠性与稳定性是非常重要的。因此哪怕是简单的代码，也要考虑可能出现的问题，并对这些问题做相关处理。</strong></p><h2 id="references">References</h2><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.cnblogs.com/an-wen/p/11180076.html">学习 HTTP 协议</a> ⭐⭐⭐ <a target="_blank" rel="noopener external nofollow noreferrer" href="http://www.dedenotes.com/html/url-fragment.html">URL 锚点、fragment 锚部分、锚点定位的九点知识</a> ⭐⭐ <a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/caryee89/article/details/7398088">统一资源定位符 URL</a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/Selina_lxh/article/details/121840190">URL(统一资源定位符)各部分详解</a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.bilibili.com/video/BV1pt41137qK?p=7">Python 爬虫视频教程全集 | bilibili</a> ⭐⭐⭐ <a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/qq_29339467/article/details/105342399">Python 爬虫教程中转站</a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/pittpakk/article/details/81218566">python3 requests 详解</a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/275695831">http 请求中 get 和 post 方法的区别</a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/370768951">python 爬虫-百度搜索结果爬取</a></p></div><footer class="post-footer"><div class="reward-container"><div>Buy me a coffee</div><button>赞赏</button><div class="post-reward"><div><img src="/images/wechatpay.jpg" alt="1nnoh 微信"> <span>微信</span></div><div><img src="/images/alipay.png" alt="1nnoh 支付宝"> <span>支付宝</span></div></div></div><div class="post-copyright"><ul><li class="post-copyright-author"><strong>本文作者： </strong>1nnoh</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="https://1nnoh.top/2F4301H/" title="爬虫与网络编程基础-Task02：HTTP 协议与 Requests">https://1nnoh.top/2F4301H/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener external nofollow noreferrer" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="post-tags"><a href="/tags/Coggle-30-Days-of-ML/" rel="tag"><i class="fa fa-tag"></i> Coggle 30 Days of ML</a> <a href="/tags/Spider/" rel="tag"><i class="fa fa-tag"></i> Spider</a> <a href="/tags/Network-Programming/" rel="tag"><i class="fa fa-tag"></i> Network Programming</a></div><div class="post-nav"><div class="post-nav-item"><a href="/25S7X1E/" rel="prev" title="阿里灵杰_Task01_环境配置与实践数据下载"><i class="fa fa-chevron-left"></i> 阿里灵杰_Task01_环境配置与实践数据下载</a></div><div class="post-nav-item"><a href="/280EQA3/" rel="next" title="矢量语义与嵌入之 TF-IDF 检索">矢量语义与嵌入之 TF-IDF 检索 <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments gitalk-container"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2022</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">1nnoh</span></div><div class="wordcount"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i> </span><span title="站点总字数">63k</span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">4:46</span></span></div><div class="busuanzi-count"><span class="post-meta-item" id="busuanzi_container_site_pv"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div><script color="0,0,255" opacity="0.5" zindex="-1" count="99" src="https://lib.baomitu.com/canvas-nest.js/1.0.1/canvas-nest.js"></script><script src="/js/prism/prism.js" async></script><script src="/js/prism/prism.js" async></script></div></footer><div class="toggle sidebar-toggle" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div><div class="sidebar-dimmer"></div><div class="back-to-top" role="button" aria-label="返回顶部"><i class="fa fa-arrow-up fa-lg"></i> <span>0%</span></div><div class="reading-progress-bar"></div><a role="button" class="book-mark-link book-mark-link-fixed"></a> <a href="https://github.com/1nnoh" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener external nofollow noreferrer" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script size="150" alpha="0.26" zindex="-2" src="https://lib.baomitu.com/ribbon.js/1.0.2/ribbon.min.js"></script><script src="https://lib.baomitu.com/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script><script src="https://lib.baomitu.com/medium-zoom/1.0.6/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script><script src="https://lib.baomitu.com/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script><script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="https://lib.baomitu.com/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script><script src="/js/third-party/search/local-search.js"></script><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script><script src="/js/third-party/math/mathjax.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/gitalk/1.8.0/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous"><script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"1nnoh","repo":"1nnoh.github.io","client_id":"19227156b4ef17fefc34","client_secret":"2d052e6865196020dd941e7bacedbb7b85880af7","admin_user":"1nnoh","distraction_free_mode":true,"proxy":"https://frolicking-zabaione-1b2f6e.netlify.app/github_access_token","language":"zh-CN","js":{"url":"https://lib.baomitu.com/gitalk/1.8.0/gitalk.min.js","integrity":"sha256-MVK9MGD/XJaGyIghSVrONSnoXoGh3IFxLw0zfvzpxR4="},"path_md5":"39d5355d928a4aefcb0818c832cb6823"}</script><script src="/js/third-party/comments/gitalk.js"></script></body></html>