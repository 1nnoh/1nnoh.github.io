<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222" media="(prefers-color-scheme: light)"><meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0"><link rel="preconnect" href="https://fonts.loli.net" crossorigin><link rel="preconnect" href="https://lib.baomitu.com" crossorigin><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png"><link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Noto+Serif+SC:300,300italic,400,400italic,700,700italic%7CLato:300,300italic,400,400italic,700,700italic%7C'Noto+Sans':300,300italic,400,400italic,700,700italic%7Csans-serif:300,300italic,400,400italic,700,700italic%7C'Noto+Sans+SC':300,300italic,400,400italic,700,700italic%7CRoboto+Serif:300,300italic,400,400italic,700,700italic%7CSource+Code+Pro:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="https://lib.baomitu.com/font-awesome/6.2.0/css/all.min.css" integrity="sha256-AbA177XfpSnFEvgpYu1jMygiLabzPCJCRIBtR5jGc0k=" crossorigin="anonymous"><script class="next-config" data-name="main" type="application/json">{"hostname":"1nnoh.top","root":"/","images":"/images","scheme":"Mist","darkmode":"auto","version":"8.13.2","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"width":269},"copycode":{"enable":false,"style":"flat"},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":{"gitalk":{"order":-1}}},"stickytabs":false,"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script><link rel="stylesheet" href="/js/prism/prism.css"><meta name="description" content="0x04 评估指标以一个例子开始。假设我们有一个汉堡分类器，可以针对图片分类，分为是汉堡，或者不是汉堡。如果我们想知道，这个分类器的效果到底如何？该如何评价呢？"><meta property="og:type" content="article"><meta property="og:title" content="2.2 逻辑回归-part2"><meta property="og:url" content="https://1nnoh.top/12PWF3V/index.html"><meta property="og:site_name" content="1nnoh&#39;s Blog"><meta property="og:description" content="0x04 评估指标以一个例子开始。假设我们有一个汉堡分类器，可以针对图片分类，分为是汉堡，或者不是汉堡。如果我们想知道，这个分类器的效果到底如何？该如何评价呢？"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120055418.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120056405.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120100205.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208121014801.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120128981.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120147145.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120149695.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120152855.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120158228.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120218387.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120254926.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120300041.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120303562.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120313244.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120326604.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120511398.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120531769.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120550009.png"><meta property="article:published_time" content="2022-11-16T07:51:26.000Z"><meta property="article:modified_time" content="2022-11-16T07:51:26.000Z"><meta property="article:author" content="1nnoh"><meta property="article:tag" content="FunRec"><meta property="article:tag" content="ML"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120055418.png"><link rel="canonical" href="https://1nnoh.top/12PWF3V/"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://1nnoh.top/12PWF3V/","path":"12PWF3V/","title":"2.2 逻辑回归-part2"}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>2.2 逻辑回归-part2 | 1nnoh's Blog</title><script src="/js/third-party/analytics/baidu-analytics.js"></script><script async src="https://hm.baidu.com/hm.js?b20166297c5501f4ebb46c56425f8cb4"></script><script async defer data-website-id="" src=""></script><script defer data-domain="" src=""></script><link rel="stylesheet" href="/js/prism/prism.css"><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript><style>mjx-container[jax=SVG]{direction:ltr}mjx-container[jax=SVG]>svg{overflow:visible}mjx-container[jax=SVG][display=true]{display:block;text-align:center;margin:1em 0}mjx-container[jax=SVG][justify=left]{text-align:left}mjx-container[jax=SVG][justify=right]{text-align:right}g[data-mml-node=merror]>g{fill:red;stroke:red}g[data-mml-node=merror]>rect[data-background]{fill:#ff0;stroke:none}g[data-mml-node=mtable]>line[data-line]{stroke-width:70px;fill:none}g[data-mml-node=mtable]>rect[data-frame]{stroke-width:70px;fill:none}g[data-mml-node=mtable]>.mjx-dashed{stroke-dasharray:140}g[data-mml-node=mtable]>.mjx-dotted{stroke-linecap:round;stroke-dasharray:0,140}g[data-mml-node=mtable]>svg{overflow:visible}[jax=SVG] mjx-tool{display:inline-block;position:relative;width:0;height:0}[jax=SVG] mjx-tool>mjx-tip{position:absolute;top:0;left:0}mjx-tool>mjx-tip{display:inline-block;padding:.2em;border:1px solid #888;font-size:70%;background-color:#f8f8f8;color:#000;box-shadow:2px 2px 5px #aaa}g[data-mml-node=maction][data-toggle]{cursor:pointer}mjx-status{display:block;position:fixed;left:1em;bottom:1em;min-width:25%;padding:.2em .4em;border:1px solid #888;font-size:90%;background-color:#f8f8f8;color:#000}foreignObject[data-mjx-xml]{font-family:initial;line-height:normal;overflow:visible}.MathJax path{stroke-width:3}mjx-container[display=true]{overflow:auto hidden}mjx-container[display=true]+br{display:none}</style></head><body itemscope itemtype="http://schema.org/WebPage"><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><p class="site-title">1nnoh's Blog</p><i class="logo-line"></i></a></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" maxlength="80" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close" role="button"><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class="search-result-icon"><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#0x04-%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="nav-text">0x04 评估指标</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5-Confusion-Matrix"><span class="nav-text">1. 混淆矩阵 Confusion Matrix</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E5%87%86%E7%A1%AE%E7%8E%87%EF%BC%8C%E7%B2%BE%E7%A1%AE%E7%8E%87%EF%BC%8C%E5%8F%AC%E5%9B%9E%E7%8E%87%EF%BC%8CF1-%E5%80%BC"><span class="nav-text">2. 准确率，精确率，召回率，F1 值</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-%E4%BA%8C%E5%88%86%E7%B1%BB"><span class="nav-text">2.1. 二分类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-%E5%A4%9A%E5%88%86%E7%B1%BB"><span class="nav-text">2.2. 多分类</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-ROC-%E6%9B%B2%E7%BA%BF%E5%92%8C-AUC-%E5%80%BC"><span class="nav-text">3. ROC 曲线和 AUC 值</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-ROC-%E6%9B%B2%E7%BA%BF"><span class="nav-text">3.1. ROC 曲线</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-AUC-%E5%80%BC"><span class="nav-text">3.2. AUC 值</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-PR-%E6%9B%B2%E7%BA%BF"><span class="nav-text">4. PR 曲线</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#0x05-%E5%AE%9E%E8%B7%B52%EF%BC%9A%E5%9F%BA%E4%BA%8E%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E4%B8%AA%E6%80%A7%E5%8C%96%E6%8E%92%E5%BA%8F"><span class="nav-text">0x05 实践2：基于逻辑回归的个性化排序</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E6%A1%88%E4%BE%8B%E6%8F%8F%E8%BF%B0"><span class="nav-text">1. 案例描述</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B"><span class="nav-text">1.1. 开发流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-text">1.2. 数据集</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-text">2. 数据预处理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-%E5%90%88%E5%B9%B6%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-text">2.1. 合并数据集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-%E5%88%B6%E4%BD%9C%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-text">2.2. 制作数据集</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="nav-text">3. 训练模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="nav-text">4. 评估指标</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-PR-%E6%9B%B2%E7%BA%BF"><span class="nav-text">4.1. PR 曲线</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-AUC"><span class="nav-text">4.2. AUC</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#0x06-%E9%9D%A2%E8%AF%95%E9%A2%98"><span class="nav-text">0x06 面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References"><span class="nav-text">References</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="1nnoh" src="/images/avatar.jpg"><p class="site-author-name" itemprop="name">1nnoh</p><div class="site-description" itemprop="description">如常.</div></div><div class="site-state-wrap site-overview-item animated"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">19</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">8</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">10</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author site-overview-item animated"><span class="links-of-author-item"><a href="https://github.com/1nnoh" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;1nnoh" rel="noopener external nofollow noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:jhhou.cn@gmail.com" title="E-Mail → mailto:jhhou.cn@gmail.com" rel="noopener external nofollow noreferrer" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a></span></div><div class="cc-license site-overview-item animated" itemprop="license"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener external nofollow noreferrer" target="_blank"><img src="https://lib.baomitu.com/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a></div></div></div></div></aside></div><div class="main-inner post posts-expand"><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://1nnoh.top/12PWF3V/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="1nnoh"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="1nnoh's Blog"><meta itemprop="description" content="如常."></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="2.2 逻辑回归-part2 | 1nnoh's Blog"><meta itemprop="description" content=""></span><header class="post-header"><h1 class="post-title" itemprop="name headline">2.2 逻辑回归-part2</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2022-11-16 15:51:26" itemprop="dateCreated datePublished" datetime="2022-11-16T15:51:26+08:00">2022-11-16</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/FunRec/" itemprop="url" rel="index"><span itemprop="name">FunRec</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/FunRec/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" itemprop="url" rel="index"><span itemprop="name">02-机器学习与深度学习基础</span></a> </span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv"><span class="post-meta-item-icon"><i class="far fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span id="busuanzi_value_page_pv"></span> </span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>6k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>27 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><h2 id="0x04-评估指标"><a href="#0x04-评估指标" class="headerlink" title="0x04 评估指标"></a>0x04 评估指标</h2><p>以一个例子开始。假设我们有一个<strong>汉堡分类器</strong>，可以针对图片分类，分为是汉堡，或者不是汉堡。如果我们想知道，这个<strong>分类器的效果</strong>到底如何？该如何评价呢？</p><span id="more"></span><p>我们将手机里的照片输入分类器，得到分类结果：<br><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120055418.png"><br><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120056405.png"></p><p>可如果样本（照片）很多的时候，这将会是一个非常大的表格。如何更加简洁的表示呢？=&gt; ==混淆矩阵 Confusion Matrix==</p><h3 id="1-混淆矩阵-Confusion-Matrix"><a href="#1-混淆矩阵-Confusion-Matrix" class="headerlink" title="1. 混淆矩阵 Confusion Matrix"></a>1. 混淆矩阵 Confusion Matrix</h3><p><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120100205.png"></p><p>如图，仅用一个 2x2 的混淆矩阵就可以解决这个问题。左上角是真实类别为 Positive 样本，同时分类器预测结果也为 Positive 的样本数量统计，因此叫 True Positive，即真正样本。而右上角是真实类别为 Negative 样本，而分类器预测为 Positive 样本（即预测错了，将不是 Positive 样本的，预测为了 Positive 样本），因此叫他 False Positive，即伪正样本。第二行矩阵同理。</p><blockquote><p>这里是从预测的角度来命名的。</p><ul><li>把正样本预测对了，就是 TP，真正样本；预测错了就是 FP，伪正样本。</li><li>把负样本预测对了，就是 TN，真负样本；预测错了就是 FN，伪负样本。</li></ul></blockquote><p>推广到多分类也是一样：<br><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208121014801.png"></p><p>主对角线上是预测正确的样本数，我们会希望主对角线上的数值尽可能的大。</p><h3 id="2-准确率，精确率，召回率，F1-值"><a href="#2-准确率，精确率，召回率，F1-值" class="headerlink" title="2. 准确率，精确率，召回率，F1 值"></a>2. 准确率，精确率，召回率，F1 值</h3><p>如果有两个或者多个<strong>汉堡分类器</strong>，如何评估他们的效果呢？</p><h4 id="2-1-二分类"><a href="#2-1-二分类" class="headerlink" title="2.1. 二分类"></a>2.1. 二分类</h4><ol><li>如果我们关心这个分类器到底<strong>分对了多少</strong>？<br><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120128981.png"></li></ol><p>准确率 (Accuracy) = (1+5) / (1+2+1+5) = 0.67</p><blockquote><p>预测正确的样本数（TP+TN），除以样本总数<br>分类正确的汉堡，除以样本总数</p></blockquote><ol start="2"><li>假设在图片搜索引擎中，我们搜索汉堡，我们关心搜索返回的汉堡图片中，<strong>有多少是 True 的汉堡图片</strong>？（返回的图片中正确的有多少？）</li></ol><p>精确率 (Precision) = 1 / (1+2) = 0.33</p><blockquote><p>预测正确的正样本数（TP），除以预测为正样本的总数（TP+FP）<br>搜索引擎返回的正确的汉堡图片数量，除以返回的所有图片数量（因为返回给你的图片，就是搜索引擎预测为汉堡的图片，虽然其中有预测错误的）</p></blockquote><ol start="3"><li>假设还是在图片搜索引擎中搜索汉堡，我们关心，<strong>有多少的汉堡图片是被找到的</strong>，有多少是没有被找到的？</li></ol><p>召回率 (Recall) = 1 / (1+1) = 0.50</p><blockquote><p>预测正确的正样本数（TP），除以正样本总数（TP+FN）<br>搜索引擎返回的正确的汉堡图片数量，除以数据库中的所有汉堡图片数量</p></blockquote><p>可以发现<strong>精确率</strong>与<strong>召回率</strong>之间，是一种此消彼长的关系。</p><ol start="4"><li>F1 值</li></ol><p>假设一种极端情况：分类器将所有样本都预测为汉堡。<br><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120147145.png"></p><p>所以不能单一地追求精确率或者召回率的数值高，需要平衡这两个指标。因此有这样一个指标——F1 值，对 P 和 R 做调和平均。<br><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120149695.png"></p><p>F1 值是<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.65ex" xmlns="http://www.w3.org/2000/svg" width="2.548ex" height="2.188ex" role="img" focusable="false" viewBox="0 -680 1126.2 967.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g><g data-mml-node="mi" transform="translate(676,-150) scale(0.707)"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g></g></g></g></svg></mjx-container>的特殊情况（<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.439ex" xmlns="http://www.w3.org/2000/svg" width="5.429ex" height="2.034ex" role="img" focusable="false" viewBox="0 -705 2399.6 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g><g data-mml-node="mo" transform="translate(843.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1899.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container>，认为 P 和 R 一样重要）。<br><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120152855.png"></p><p><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.439ex" xmlns="http://www.w3.org/2000/svg" width="1.281ex" height="2.034ex" role="img" focusable="false" viewBox="0 -705 566 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g></g></g></svg></mjx-container>值应该怎么取呢？</p><ul><li>比如在医疗领域，我们不希望遗漏任何一个患者，即认为 Recall 更重要<ul><li>此时一般<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.439ex" xmlns="http://www.w3.org/2000/svg" width="1.281ex" height="2.034ex" role="img" focusable="false" viewBox="0 -705 566 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g></g></g></svg></mjx-container>取为 2</li></ul></li><li>如果在其他领域，我们认为 Precession 更重要<ul><li>此时一般<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.439ex" xmlns="http://www.w3.org/2000/svg" width="1.281ex" height="2.034ex" role="img" focusable="false" viewBox="0 -705 566 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g></g></g></svg></mjx-container>取在 (0, 1] 之间</li></ul></li></ul><p><strong>小结</strong><br><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120158228.png"></p><h4 id="2-2-多分类"><a href="#2-2-多分类" class="headerlink" title="2.2. 多分类"></a>2.2. 多分类</h4><p><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120218387.png"></p><ul><li>宏观<ul><li>Accuracy 依然是绿色方格（主对角线）的预测正确样本 / 总样本数。</li><li>[Precision, Recall, F1] 是计算每一个类别自己的 [P, R, F1]。<ul><li>比如计算 C3 的 Precision = (C3, C3)绿色方格 / 预测类别 C3 一整行的样本总数</li><li>C3 的 Recall = (C3, C3)绿色方格 / 真实类别 C3 一整列 的样本总数</li></ul></li><li>随后整体的 [P, R, F1] 通过对每一类的 [P, R, F1] 加起来求平均，或者做一个加权平均得到。</li></ul></li><li>微观<ul><li><strong>Accuracy = micro precision = micro recall = micro F1-score</strong></li><li>把每个类别的 TP, FP, FN 先相加之后，再根据二分类的公式进行计算。<ul><li>比如还是对 C3 来说<ul><li>(C3, C3)绿色方格 为 TP （预测正确的正样本）</li><li>预测类别为 C3 的行上其他项，为 FP （伪正样本）</li><li>真实类别为 C3 的列上其他项，为 FN （伪负样本）</li></ul></li><li>将所有类别的 TP, FP, FN 先相加，然后根据二分类公式计算<ul><li>比如<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-1.045ex" xmlns="http://www.w3.org/2000/svg" width="39.696ex" height="3.172ex" role="img" focusable="false" viewBox="0 -940 17545.6 1402.1"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g><g data-mml-node="mi" transform="translate(1051,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1396,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(1829,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2280,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mo" transform="translate(2987.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(3987.4,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mo" transform="translate(5016.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(6072,0)"><g data-mml-node="mrow" transform="translate(3131.8,457.1) scale(0.707)"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="msub" transform="translate(704,0)"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(675,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mn" transform="translate(760,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2320,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(3098,0)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="msub" transform="translate(3802,0)"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(675,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mn" transform="translate(760,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mo" transform="translate(5417.9,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mo" transform="translate(6195.9,0)"><path data-c="2026" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-345) scale(0.707)"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="msub" transform="translate(704,0)"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(675,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mn" transform="translate(760,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2320,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(3098,0)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="msub" transform="translate(3802,0)"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(675,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mn" transform="translate(760,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mo" transform="translate(5417.9,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mo" transform="translate(6195.9,0)"><path data-c="2026" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z"></path></g><g data-mml-node="mo" transform="translate(7367.9,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(8145.9,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g><g data-mml-node="msub" transform="translate(8894.9,0)"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(675,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mn" transform="translate(760,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(10510.9,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(11288.9,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g><g data-mml-node="msub" transform="translate(12037.9,0)"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(675,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mn" transform="translate(760,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g><g data-mml-node="mo" transform="translate(13653.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mo" transform="translate(14431.8,0)"><path data-c="2026" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z"></path></g></g><rect width="11233.6" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></li></ul></li></ul></li></ul></li></ul><p>微观比较难理解，<a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/147663370">可以参考这里</a>。</p><h3 id="3-ROC-曲线和-AUC-值"><a href="#3-ROC-曲线和-AUC-值" class="headerlink" title="3. ROC 曲线和 AUC 值"></a>3. ROC 曲线和 AUC 值</h3><h4 id="3-1-ROC-曲线"><a href="#3-1-ROC-曲线" class="headerlink" title="3.1. ROC 曲线"></a>3.1. ROC 曲线</h4><p>依然是汉堡问题。分类器做预测的时候，输出的是一个在 (0, 1) 的预测值，我们通过设定一个<strong>阈值</strong>，将这个连续值转为 0 或 1 的离散值。如图，如果我们设定阈值为 0.5，那么可以得到唯一一个与之对应的<strong>混淆矩阵</strong>。<br><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120254926.png"></p><p>可以想像，如果我们将这个阈值，从左到右（从 0 到 1）都取一遍，<strong>就会得到很多个混淆矩阵</strong>。<br><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120300041.png"></p><p>那么有没有办法可以==将这所有的混淆矩阵，表示在一个二维平面内呢==？</p><p>=&gt; <strong>ROC 曲线</strong><br><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120303562.png"></p><p>如图，每个混淆矩阵都有他的 TP，FP，FN，TN 值，那么可以计算得到<strong>真阳率</strong>（True Positive Rate, TPR）与<strong>假阳率</strong>（False Positive Rate, FPR）。如果将这两个值映射到二维平面，FPR 作为横坐标，TPR 作为纵坐标。<strong>此时一个混淆矩阵就被表示为了二维平面上的一个点</strong>。如果将所有的混淆矩阵的点都表示在这个二维坐标系中，就可以拟合一条曲线，即 <strong>ROC 曲线</strong>。</p><blockquote><ul><li>ROC 曲线描述了 TPR 与 FPR 的关系</li><li>真阳率 TPR: 正样本中猜对的比例</li></ul></blockquote><h4 id="3-2-AUC-值"><a href="#3-2-AUC-值" class="headerlink" title="3.2. AUC 值"></a>3.2. AUC 值</h4><p>如果有 A，B 两个分类器，并且有他们的 ROC 曲线，应该如何判断哪个分类器的效果好呢？<br><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120313244.png"></p><p>可以从 TPR 与 FPR 分析入手。观察公式发现，TPR 与 FPR 的分母分别是<strong>数据集中正样本个数与负样本个数</strong>，也就是说这两个值是已经确定的。因为无论取什么阈值，得到哪个混淆矩阵，这两个值都不会变（因为数据集已经给定，不会变）。</p><p>所以 <strong>TPR 与 FPR 仅同他们的分子</strong>相关。</p><ul><li>TPR 的分子 TP = count(真正样本)</li><li>FPR 的分子 FP = count(伪正样本)。<br>自然是分类正确的正样本数 <strong>TP 越大越好</strong>，分类错误的正样本数 <strong>FP 越小越好</strong>。即<strong>TPR 尽可能的大，FPR 尽可能的小</strong>。反应到二维平面上就是，ROC 曲线越靠近左上角，说明分类器效果越好。</li></ul><blockquote><p>或者说，<strong>正样本中猜对的比例——真阳率 TPR</strong> 越高越好。</p></blockquote><p>那么有没有数值可以量化这种曲线靠近左上角的程度呢？</p><p>那就是 <strong>=&gt; AUC 值（Area Under the roc Curve）</strong>。<br><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120326604.png"></p><ul><li>AUC 的定义：AUC 描述 ROC 曲线下包围的面积。AUC 值在 (0, 1) 的区间内。</li><li>AUC 的意义：<ul><li>随机取一对正负样本，AUC 是把正样本预测为 1 的概率，大于把负样本预测为 1 的概率。<strong>或者如前面所说，正确预测一个正样本的概率</strong>。</li><li>公式如下：<ul><li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.72ex" xmlns="http://www.w3.org/2000/svg" width="24.325ex" height="2.417ex" role="img" focusable="false" viewBox="0 -750 10751.5 1068.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(750,0)"><path data-c="1D448" d="M107 637Q73 637 71 641Q70 643 70 649Q70 673 81 682Q83 683 98 683Q139 681 234 681Q268 681 297 681T342 682T362 682Q378 682 378 672Q378 670 376 658Q371 641 366 638H364Q362 638 359 638T352 638T343 637T334 637Q295 636 284 634T266 623Q265 621 238 518T184 302T154 169Q152 155 152 140Q152 86 183 55T269 24Q336 24 403 69T501 205L552 406Q599 598 599 606Q599 633 535 637Q511 637 511 648Q511 650 513 660Q517 676 519 679T529 683Q532 683 561 682T645 680Q696 680 723 681T752 682Q767 682 767 672Q767 650 759 642Q756 637 737 637Q666 633 648 597Q646 592 598 404Q557 235 548 205Q515 105 433 42T263 -22Q171 -22 116 34T60 167V183Q60 201 115 421Q164 622 164 628Q164 635 107 637Z"></path></g><g data-mml-node="mi" transform="translate(1517,0)"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mo" transform="translate(2554.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(3610.6,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mo" transform="translate(4361.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(4750.6,0)"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(675,-176.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">正</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">正</text></g></g></g><g data-mml-node="mo" transform="translate(7167.5,0)"><path data-c="3E" d="M84 520Q84 528 88 533T96 539L99 540Q106 540 253 471T544 334L687 265Q694 260 694 250T687 235Q685 233 395 96L107 -40H101Q83 -38 83 -20Q83 -19 83 -17Q82 -10 98 -1Q117 9 248 71Q326 108 378 132L626 250L378 368Q90 504 86 509Q84 513 84 520Z"></path></g><g data-mml-node="msub" transform="translate(8223.3,0)"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(675,-176.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">正</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">负</text></g></g></g><g data-mml-node="mo" transform="translate(10362.5,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></li><li>其中<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.72ex" xmlns="http://www.w3.org/2000/svg" width="4.84ex" height="2.265ex" role="img" focusable="false" viewBox="0 -683 2139.2 1001.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(675,-176.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">正</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">正</text></g></g></g></g></g></svg></mjx-container>代表将该正样本预测为 1 的概率，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.72ex" xmlns="http://www.w3.org/2000/svg" width="4.84ex" height="2.265ex" role="img" focusable="false" viewBox="0 -683 2139.2 1001.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(675,-176.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">正</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">负</text></g></g></g></g></g></svg></mjx-container>代表将该负样本预测为 1 的概率。</li></ul></li></ul></li></ul><blockquote><p><strong>AUC 值也可以理解为（按照预测值做从小到大的排序后）负样本排在正样本前面的概率。</strong>（或者反过来）</p><p>结合实践 2 中的 AUC 实现可以更好的理解这句话。</p><ul><li>假设有一个文件，每行代表一个样本，左列真实值，右列预测值。按照右列，从小到大排序。</li><li>那么此时，最理想的情况是——左列是全都预测正确，先全是 0，后面全是 1。<ul><li>因为右边预测值从小到大排序，全部预测正确的话必然是这样。</li><li>此时<strong>所有的负样本都排在了正样本前面</strong>。即负样本排在正样本前面的概率为 1。即 AUC = 1。</li></ul></li><li>但是，假如第 7 行，预测值为 0.03，真实值为 1。<ul><li>也就是说预测错了，有一个正样本被排到了前面。那么 AUC 就会减小。</li><li>并且越多的正样本排到了负样本前面，说明错的越多，AUC 也会越小。</li></ul></li></ul></blockquote><blockquote><p>AUC 反应了整体样本间的排序能力。<br>此外还有 GAUC(Group AUC)，计算每个用户的 AUC，然后加权平均。GAUC 关注的是每个用户的排序结果。</p></blockquote><h3 id="4-PR-曲线"><a href="#4-PR-曲线" class="headerlink" title="4. PR 曲线"></a>4. PR 曲线</h3><p>如果<strong>将 ROC 曲线的 TPR 与 FPR 换成 Precision 与 Recall</strong>，就得到了 PR 曲线。所以每个 PR 曲线上的点，也是与相应的混淆矩阵对应的。并且我们知道，Precision 与 Recall 一起越大越好，因此 PR 曲线越靠近右上角越好。如下图。<br><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120511398.png"></p><blockquote><ul><li>ROC 曲线描述了 Precision 与 Recall 的关系</li><li>所以 PR 曲线也可以看作取不同的阈值，得到不同的混淆矩阵，计算得到不同的 Precision 与 Recall 映射到二维空间，然后拟合出来的曲线。</li></ul></blockquote><p>那么应该什么时候用 PR 曲线，什么时候用 ROC 曲线呢？<br><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120531769.png"></p><p>如图，对于两种曲线，他们的横坐标轴是一样的，TPR = Recall。区别只在于 FPR 和 Precision。</p><ul><li>假设，有两个分类器<ul><li>分类器 A 得到的 FP 为 10 倍的 TP，但远小于负样本数 N</li><li>分类器 B 得到的 FP 为 100 倍的 TP，但远小于负样本数 N</li></ul></li><li>对这两个分类器的 FPR 与 Precision 做差值<ul><li>FPR 差值约等于 0，因为 TP 远小于 N。</li><li>Precision 差值约为 0.081。这个差值与 FP 强相关。<strong>而 FP 代表着，本该是负例，却被错误预测为正例的数量，说明对正例更加关心。</strong></li></ul></li><li>从 FPR 与 Precision 本身的含义理解<ul><li>FPR：有多少负样本的被预测为正样本（预测错误）；也可以看作，有多少负样本预测正确了。</li><li>Precision：预测为正样本的样本中，有多少是正确预测的。</li></ul></li></ul><p>举一个例子，假设有这样一组极度不平衡的数据（左下角写错了，应该是负例：493；正例：7）。<br><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202208120550009.png"></p><p>可以看到，正例一个都没预测对。但如果看左边的 ROC 曲线的话，好像效果还蛮好的。右边的 PR 曲线，反映了正例预测的效果差。</p><p>==因此，当我们更加关心正例的预测结果，而且数据极度不平衡时，我们一定要用 PR 曲线，而不是 ROC 曲线。==</p><h2 id="0x05-实践2：基于逻辑回归的个性化排序"><a href="#0x05-实践2：基于逻辑回归的个性化排序" class="headerlink" title="0x05 实践2：基于逻辑回归的个性化排序"></a>0x05 实践2：基于逻辑回归的个性化排序</h2><h3 id="1-案例描述"><a href="#1-案例描述" class="headerlink" title="1. 案例描述"></a>1. 案例描述</h3><p>当用户浏览商品时，需要对这些商品做个性化排序。即对所有商品做一个打分，然后排序。在本案例，是预测一首歌曲用户是否喜欢。喜欢为 1，不喜欢为 0。也可以做个性化排序，因为预测值在 (0, 1) 区间中，那么将分数高的歌放在前面，用户有更大的可能性会喜欢。</p><h4 id="1-1-开发流程"><a href="#1-1-开发流程" class="headerlink" title="1.1. 开发流程"></a>1.1. 开发流程</h4><blockquote><p>数据采集(数据集): 用户画像，商品信息，用户行为<br>数据预处理: 将数据处理为样本数据集——可以提供给模型训练的数据<br>训练算法: 使用逻辑回归做二分类<br>评估算法: 获得预测值，然后通过 PR 曲线，AUC 指标进行评估</p></blockquote><h4 id="1-2-数据集"><a href="#1-2-数据集" class="headerlink" title="1.2. 数据集"></a>1.2. 数据集</h4><ol><li><p>用户行为数据 <code>ranking_lr/data/user_watch_pref.sml</code></p><pre class="line-numbers language-css" data-language="css"><code class="language-css">包含以下字段：
userid<span class="token punctuation">,</span> itemid<span class="token punctuation">,</span> watch_len<span class="token punctuation">,</span> hour
userid<span class="token punctuation">,</span> itemid<span class="token punctuation">,</span> 用户对 item 收听时长<span class="token punctuation">,</span> 点击时间（小时）

01e069ed67600f1914e64c0fe7730944^A4090309101^A15^A19
01d86fc1401b283d5828c293be290e08^A6192809101^A75^A12
002f4b9c49be9a0b2c13e1c3c4f6a21c^A8915109101^A385^A18
01e3fdf415107cd6046a07481fbed499^A6470209102^A1635^A21
01e3fdf415107cd6046a07481fbed499^A6470209102^A555^A16
01e3fdf415107cd6046a07481fbed499^A6470209102^A2024^A22
......<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>歌曲元数据 <code>ranking_lr/data/music_meta</code></p><pre class="line-numbers language-css" data-language="css"><code class="language-css">包含以下字段：
itemid<span class="token punctuation">,</span> name<span class="token punctuation">,</span> desc<span class="token punctuation">,</span> total_timelen<span class="token punctuation">,</span> location<span class="token punctuation">,</span> tags
itemid<span class="token punctuation">,</span> name<span class="token punctuation">,</span> 内容<span class="token punctuation">,</span> 时长<span class="token punctuation">,</span> 地域<span class="token punctuation">,</span> 标签

0093709100^A韩国少女时代最新回归新专主打《I GOT A BOY》^A韩国少女时代最新回归新专主打《I GOT A BOY》^A304^A^A
0102209100^A韩国张力尹携手EXO成员CHEN《呼吸》中文版^A韩国张力尹携手EXO成员CHEN《呼吸》中文版^A274^A^ACHEN<span class="token punctuation">,</span>少&gt;
029900100^A徐颢菲《猫的借口》^A^A284^A国内^A
0368709100^A美女翻唱 别问我是谁^A美女翻唱 别问我是谁^A288^A^A流行歌曲<span class="token punctuation">,</span>翻唱<span class="token punctuation">,</span>网络歌曲<span class="token punctuation">,</span>美女<span class="token punctuation">,</span>舞曲<span class="token punctuation">,</span>社会
0603409100^A龙梅子<span class="token punctuation">,</span>老猫 老爸老爸你好吗^A龙梅子<span class="token punctuation">,</span>老猫 老爸老爸你好吗^A259^A^A你好吗<span class="token punctuation">,</span>龙梅子<span class="token punctuation">,</span>老猫<span class="token punctuation">,</span>老爸老爸
0637909100^A《中国好歌曲》  诙?镜诹?赸-韩磊天边》^A《中国好歌曲》  诙?镜诹?赸-韩磊天边》^A289^A^A中国好歌曲<span class="token punctuation">,</span>&gt;
......<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><p>第一列是 <code>歌曲id</code>，后面几列是歌曲的一些信息。而且有的歌曲某些信息是缺失的，这里是以 <code>^A</code> 作为分隔符，所以出现相连的两个分隔符时，如 <code>^A^A</code>，就说明其中的 Tag 缺失了。</p><blockquote><p>补充：<code>^A</code> 的编码是 <code>'\001'</code></p></blockquote><ol start="3"><li>用户画像 <code>ranking_lr/data/merge_base.data</code><pre class="line-numbers language-css" data-language="css"><code class="language-css">包含以下字段：
userid<span class="token punctuation">,</span> gender<span class="token punctuation">,</span> age<span class="token punctuation">,</span> salary<span class="token punctuation">,</span> location
userid<span class="token punctuation">,</span> 性别<span class="token punctuation">,</span> 年龄<span class="token punctuation">,</span> 收入<span class="token punctuation">,</span> 地域

00ea9a2fe9c6810aab440c4d8c050000<span class="token punctuation">,</span>女<span class="token punctuation">,</span>26-35<span class="token punctuation">,</span>20000-100000<span class="token punctuation">,</span>江苏
01a0ae50fd4b9ef6ed04c22a7e421000<span class="token punctuation">,</span>女<span class="token punctuation">,</span>36-45<span class="token punctuation">,</span>0-2000<span class="token punctuation">,</span>河北
002db7d2360562dd16828c4b91402000<span class="token punctuation">,</span>女<span class="token punctuation">,</span>46-100<span class="token punctuation">,</span>5000-10000<span class="token punctuation">,</span>云南
006a184749e3b3eb83e9eb516d522000<span class="token punctuation">,</span>男<span class="token punctuation">,</span>36-45<span class="token punctuation">,</span>2000-5000<span class="token punctuation">,</span>天津
00de61c1d635ad964eef2aefa8292000<span class="token punctuation">,</span>女<span class="token punctuation">,</span>19-25<span class="token punctuation">,</span>2000-5000<span class="token punctuation">,</span>内蒙古
00d313fa79be989e330f215c39dc3000<span class="token punctuation">,</span>女<span class="token punctuation">,</span>26-35<span class="token punctuation">,</span>10000-20000<span class="token punctuation">,</span>天津
......<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h3 id="2-数据预处理"><a href="#2-数据预处理" class="headerlink" title="2. 数据预处理"></a>2. 数据预处理</h3><h4 id="2-1-合并数据集"><a href="#2-1-合并数据集" class="headerlink" title="2.1. 合并数据集"></a>2.1. 合并数据集</h4><blockquote><p>总体思路：处理原始的数据，将用户画像数据 、物品元数据、用户行为数据，3 份融合到一起，得到处理后 merge_base.data。</p></blockquote><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">cd ./pre_base_data
python gen_base.py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">#coding=utf-8
import sys

# 三类原始数据文件的路径，用户画像数据、物品元数据，用户行为数据
user_action_data = '../data/user_watch_pref.sml'
music_meta_data = '../data/music_meta'
user_profile_data = '../data/user_profile.data'

# 将合并后的元数据放到新的文件里
output_file = '../data/merge_base.data'

# 将3份数据merge后的结果输出，供下游数据处理
ofile = open(output_file, 'w')

# step 1. decode music meta data
# 将处理后的结果放入字典里面，key是itemid，value为物品对应的信息，为最后写入做准备
item_info_dict = {}
with open(music_meta_data, 'r') as fd:
    for line in fd:
        ss = line.strip().split('\001')
        if len(ss) != 6:
            continue
        itemid, name, desc, total_timelen, location, tags = ss
        item_info_dict[itemid] = '\001'.join([name, desc, total_timelen, location, tags])

# step 2. decode user profile data
# 处理用户画像数据，将处理后的结果放入字典里面，key是用户id，value是用户信息
user_profile_dict = {}
with open(user_profile_data, 'r') as fd:
    for line in fd:
        ss = line.strip().split(',')
        if len(ss) != 5:
            continue
        userid, gender, age, salary, location = ss
        user_profile_dict[userid] = '\001'.join([gender, age, salary, location])

# step 3. decode user action data &amp; output merge data
# 写入最后的信息，将用户行为数据进行处理，并把step1和step2得到的数据一并归纳在文件里面
with open(user_action_data, 'r') as fd:
    for line in fd:
        ss = line.strip().split('\001')
        if len(ss) != 4:
            continue
        userid, itemid, watch_len, hour = ss

        if userid not in user_profile_dict:
            continue

        if itemid not in item_info_dict:
            continue

        ofile.write('\001'.join([userid, itemid, watch_len, hour, \
                user_profile_dict[userid], item_info_dict[itemid]]))
        ofile.write("\n")

ofile.close()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>合并后得到如下数据 <code>ranking_lr/data/merge_base.data</code>。</p><pre class="line-numbers language-css" data-language="css"><code class="language-css">包含以下字段：
userid<span class="token punctuation">,</span> itemid<span class="token punctuation">,</span> watch_len<span class="token punctuation">,</span> hour<span class="token punctuation">,</span> user_profile_dict[userid]<span class="token punctuation">,</span> item_info_dict[itemid]
userid<span class="token punctuation">,</span> itemid<span class="token punctuation">,</span> 用户行为数据<span class="token punctuation">(</span>收听时长<span class="token punctuation">)</span><span class="token punctuation">,</span> 用户画像<span class="token punctuation">(</span>年龄<span class="token punctuation">,</span> 性别<span class="token punctuation">,</span> 收入<span class="token punctuation">,</span> 地区<span class="token punctuation">)</span><span class="token punctuation">,</span> 物品信息<span class="token punctuation">(</span>名字<span class="token punctuation">,</span> 描述<span class="token punctuation">,</span> 时长<span class="token punctuation">,</span> 标签<span class="token punctuation">)</span>

01e069ed67600f1914e64c0fe7730944^A4090309101^A15^A19^A女^A0-18^A10000-20000^A江西^A大美妞 大哲2013最新伤感歌曲网络歌曲DJ舞曲 大连翻译^A^A248^A^A大美妞<span class="token punctuation">,</span>流行
01d86fc1401b283d5828c293be290e08^A6192809101^A75^A12^A男^A26-35^A2000-5000^A广东^A李贞贤 Summer Dance MBC现场版？？？？ ？？？ ？^A^A159^A^A李贞贤<span class="token punctuation">,</span>明星
002f4b9c49be9a0b2c13e1c3c4f6a21c^A8915109101^A385^A18^A女^A36-45^A10000-20000^A广西^A音乐 《我是歌手》 周笔畅 《慢慢》第二季第五期_1^A音乐 《我是歌手》 周笔畅 《慢慢》第二季第五期_1^A314^A^A邓紫棋<span class="token punctuation">,</span>我是歌手第二季<span class="token punctuation">,</span>周笔畅<span class="token punctuation">,</span>音乐<span class="token punctuation">,</span>我是歌手<span class="token punctuation">,</span>流行
01e3fdf415107cd6046a07481fbed499^A6470209102^A1635^A21^A男^A36-45^A20000-100000^A内蒙古^A黄家驹1993演唱会高清视频^A^A1969^A^A演唱会
01e3fdf415107cd6046a07481fbed499^A6470209102^A555^A16^A男^A36-45^A20000-100000^A内蒙古^A黄家驹1993演唱会高清视频^A^A1969^A^A演唱会
01e3fdf415107cd6046a07481fbed499^A6470209102^A2024^A22^A男^A36-45^A20000-100000^A内蒙古^A黄家驹1993演唱会高清视频^A^A1969^A^A演唱会
......<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-2-制作数据集"><a href="#2-2-制作数据集" class="headerlink" title="2.2. 制作数据集"></a>2.2. 制作数据集</h4><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">cd ./pre_data_for_rankmodel
python gen_samples.py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>将之前合并的数据进一步处理，将年龄、性别等 Feature 转为 index 表示。并且把歌曲标题转为 token。得到如下数据 <code>ranking_lr/data/samples.data</code>。</p><pre class="line-numbers language-css" data-language="css"><code class="language-css">包含以下字段：
标签 label <span class="token punctuation">(</span>是否喜欢<span class="token punctuation">)</span><span class="token punctuation">,</span> 用户特征<span class="token punctuation">(</span>性别<span class="token punctuation">,</span> 年龄<span class="token punctuation">)</span><span class="token punctuation">,</span> 物品特征<span class="token punctuation">(</span>标题token<span class="token punctuation">)</span>

0 0<span class="token punctuation">:</span>1 2<span class="token punctuation">:</span>1 4702<span class="token punctuation">:</span>1.38682463766 11188<span class="token punctuation">:</span>0.996230625242 1350<span class="token punctuation">:</span>0.996230625242 5943<span class="token punctuation">:</span>0.996230625242 16069<span class="token punctuation">:</span>0.996230625242 10378<span class="token punctuation">:</span>0.793220918108 23573<span class="token punctuation">:</span>0.697935392737 11664<span class="token punctuation">:</span>0.631809128186 21965<span class="token punctuation">:</span>0.62434573841 24869<span class="token punctuation">:</span>0.517456462871 1003<span class="token punctuation">:</span>0.503245881179
1 0<span class="token punctuation">:</span>1 5<span class="token punctuation">:</span>1 7353<span class="token punctuation">:</span>1.99246125048 4324<span class="token punctuation">:</span>1.71495995655 3972<span class="token punctuation">:</span>1.64293773069 4968<span class="token punctuation">:</span>1.52451457681 19756<span class="token punctuation">:</span>1.10494485228 1118<span class="token punctuation">:</span>1.03970163946
1 1<span class="token punctuation">:</span>1 5<span class="token punctuation">:</span>1 11299<span class="token punctuation">:</span>2.64150609428 1998<span class="token punctuation">:</span>2.39095350058 1161<span class="token punctuation">:</span>2.13636036542 20762<span class="token punctuation">:</span>1.99773092931 4221<span class="token punctuation">:</span>1.61142664699
1 1<span class="token punctuation">:</span>1 5<span class="token punctuation">:</span>1 11299<span class="token punctuation">:</span>2.64150609428 1998<span class="token punctuation">:</span>2.39095350058 1161<span class="token punctuation">:</span>2.13636036542 20762<span class="token punctuation">:</span>1.99773092931 4221<span class="token punctuation">:</span>1.61142664699
1 1<span class="token punctuation">:</span>1 5<span class="token punctuation">:</span>1 11299<span class="token punctuation">:</span>2.64150609428 1998<span class="token punctuation">:</span>2.39095350058 1161<span class="token punctuation">:</span>2.13636036542 20762<span class="token punctuation">:</span>1.99773092931 4221<span class="token punctuation">:</span>1.61142664699
1 0<span class="token punctuation">:</span>1 2<span class="token punctuation">:</span>1 11299<span class="token punctuation">:</span>2.64150609428 1998<span class="token punctuation">:</span>2.39095350058 1161<span class="token punctuation">:</span>2.13636036542 20762<span class="token punctuation">:</span>1.99773092931 4221<span class="token punctuation">:</span>1.61142664699<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-训练模型"><a href="#3-训练模型" class="headerlink" title="3. 训练模型"></a>3. 训练模型</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">cd /rankmodel
python lr.py ../data/samples.data<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="4-评估指标"><a href="#4-评估指标" class="headerlink" title="4. 评估指标"></a>4. 评估指标</h3><ul><li>如何评价模型的效果？<ul><li>PR 曲线</li><li>AUC</li></ul></li></ul><h4 id="4-1-PR-曲线"><a href="#4-1-PR-曲线" class="headerlink" title="4.1. PR 曲线"></a>4.1. PR 曲线</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"># pr.py

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_curve, average_precision_score

#y_true = np.array([0, 0, 1, 1])
#y_scores = np.array([0.1, 0.5, 0.4, 0.8])

data = pd.read_csv('auc.txt')
print(data)
y_scores = data['pred']
y_true = data['true']

#画曲线
precision, recall, thresholds = precision_recall_curve(y_true, y_scores)
plt.figure("P-R Curve")
plt.title('Precision/Recall Curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.plot(recall,precision)
plt.show()

#计算AP
AP = average_precision_score(y_true, y_scores, average='macro', pos_label=1, sample_weight=None)
print('AP:', AP)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>由于这里读取的时候是用的 <code>data = pd.read_csv('auc.txt')</code>，所以要把 <code>auc.raw</code> 转为 <code>.csv</code> 格式。</p><p>首先输出预测值与真实值的数据：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">cd /rankmodel
python lr_auc.py ../data/samples.data<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>生成了两个文件，<code>ranking_lr/rankmodel/T.txt</code> 与 <code>ranking_lr/rankmodel/P.txt</code>。分别是测试集的真实值与预测值。</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">真实值：
ranking_lr/rankmodel/T.txt
# P(y=1|x)
0
0
1
0
1
1
......<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-text" data-language="text"><code class="language-text">预测值：
ranking_lr/rankmodel/P.txt
# 因为是二分类，所以预测值这里有两个列
# 左边：P(y=0|x) 右边：P(y=1|x)

[ 0.36431328  0.63568672]
[ 0.068367  0.931633]
[ 0.19792306  0.80207694]
[ 0.43181549  0.56818451]
[ 0.18593127  0.81406873]
[ 0.15577786  0.84422214]
......<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然而只需要一列的预测值就可以了，所以将 <code>P.txt</code> 中的第二列取出。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">cat P.txt | awk '{print $2}' | tr '\]' ' ' |&gt; P_2.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>解释一下这条命令做了什么。以管道符为分隔，依次解释。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">1. 输出 P.txt
cat P.txt | head

2. 将 P.txt 的第二列输出
cat P.txt | awk '{print $2}' | head
输出如下：
0.75734437]
0.87088091]
0.71707007]
 
3. 将以上输出右边的中括号替换为空字符
cat P.txt | awk '{print $2}' | tr '\]' ' ' | head

4. 将以上结果存入文件 P_2.txt
cat P.txt | awk '{print $2}' | tr '\]' ' ' |&gt; P_2.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>将真实值与预测值的文件作为两列数据合到一个文件 <code>auc.raw</code> 中</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">paste T.txt P_2.txt &gt; auc.raw<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>得到如下格式的文件：</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">1^M&gt;0.75734437·
1^M&gt;0.87088091·
0^M&gt;0.71707007·
...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到真实值与预测值之间用 <code>^M&gt;</code> 分隔，预测值右边还有一个空格。需要把这个文件改为 <code>.csv</code> 的文件格式。</p><p>用 vim 打开 <code>auc.raw</code>，然后替换。需要用到以下命令：</p><pre class="line-numbers language-vim" data-language="vim"><code class="language-vim">:{作用范围}s/{目标字符}/{替换的字符}/{替换标志}

- 目标字符：origin
- 替换的字符：new
- 作用范围：用于指定替换的范围。
	- `1,3`表示替换第一行至第三行
	- `1,$`表示替换第一行到最后一行
	- 也可以直接用`%`表示替换所有行。 
- 替换标志（可以组合使用）： 
	- c: confirm，每次替换前都会询问
	- e：不显示error 
	- g: globe，不询问，整个替换
	- i: ignore，即不区分大小写<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">vim auc.raw

:%s/ $//g  # 将全局行尾的空格去掉
:%s/^M//g  # 这里的 `^M` 要使用 `CTRL-V CTRL-M` 生成，而不是直接键入 `^M`

cp auc.raw auc.txt  # 将 auc.raw 复制到一个新的文件，因为原文件后面还有用

vim auc.txt

:%s/^I/,/g  # 这里的 `^I` 就是 vim 里显示的 `&gt;`，用 Tab 键输入。或者输入 `\t`。

# 跳转命令
:1  # 跳转到第 1 行
# 然后在第一行之前插入表头：
# true,pred

# 最终得到如下格式的文件：
# true,pred
# 1,0.75734437
# 1,0.87088091
# ...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>绘制 PR 曲线：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">python pr.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="4-2-AUC"><a href="#4-2-AUC" class="headerlink" title="4.2. AUC"></a>4.2. AUC</h4><p>计算 AUC：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">cat auc.raw | sort -t$'\t' -k2g |awk -F'\t' '($1==0){++x;a+=y;}($1==1){++y;}END{print 1.0-a/(x*y);}'

# cat auc.raw | sort -t$'\t' -k2g 对第二列数据从小到大做排序
# -F'\t' 以 '\t' 作为分隔符，第一列用 $1 表示，第二列用 $2 表示
# $1==0){++x;a+=y;} 如果满足 $1==0，那么执行大括号里的内容。
# x：负样本个数 y：正样本个数 a：错误预测样本 pair 个数
# x*y：正负样本 pair 个数
# a/x*y：错误的概率
# 1-a/x*y：正确的概率<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="0x06-面试题"><a href="#0x06-面试题" class="headerlink" title="0x06 面试题"></a>0x06 面试题</h2><blockquote><p><strong>1. 逻辑回归和朴素贝叶斯的区别？</strong></p><ul><li>逻辑回归是判别模型，朴素贝叶斯是生成模型<ul><li>判别模型：逻辑回归是直接对 P(y|x) 的问题进行建模，学习和求解，是在给定观测变量值的前提下，目标变量的==条件生成概率==。</li><li>生成模型：基于条件独立假设，在计算 P(y|x)之前，先要从训练数据中计算 P(x|y)和 P(y)的先验概率，从而利用贝叶斯公式计算 P(y|x)。需要所有变量的==全概率模型==。</li></ul></li></ul></blockquote><blockquote><p><strong>2. 线性回归和逻辑回归的区别？</strong></p><ul><li>逻辑回归是线性回归加了 Sigmoid 函数。</li><li>逻辑回归输出只取 0 和 1，线性回归输出连续值</li><li>拟合函数也有区别<ul><li>线性回归：<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.566ex" xmlns="http://www.w3.org/2000/svg" width="4.299ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 1900 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(550,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(939,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(1511,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>目标是拟合函数</li><li>逻辑回归：<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.566ex" xmlns="http://www.w3.org/2000/svg" width="14.419ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 6373 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(645,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(990,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(1467,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2345,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(2830,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3175,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(3695,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(4084,0)"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(4634,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(5023,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(5595,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(5984,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>目标是拟合对一类样本的概率</li></ul></li></ul></blockquote><blockquote><p><strong>3. 随机梯度下降（SGD）和批量梯度下降（BGD）的区别？</strong></p><ul><li>SGD 是每次随机取一个样本做梯度更新</li><li>BGD 是每次随机取一个 batch（n 个样本）做梯度更新</li></ul></blockquote><blockquote><p><strong>4. 什么是 AUC？</strong></p></blockquote><blockquote><p><strong>5. 模型中的 w 参数，为什么不宜过大？</strong></p><ul><li>因为当某一个或者某几个 w 参数过大时，会导致模型过于依赖这几个特征，使得模型的泛化性变差。</li><li>也会导致梯度更新波动较大。</li></ul></blockquote><blockquote><p><strong>6. 什么是正则化项？</strong></p><ul><li>在损失函数中添加==惩罚项（范数）==，作为约束，使得 w 保持接近 0 值，不会过大。</li><li>如果是 L1 正则化，除了缩小解空间，使模型参数尽可能接近 0；还可以过滤掉一些特征（结合 L1 的图理解），让模型变得简洁，可解释性更好。</li></ul></blockquote><blockquote><p><strong>7. 过拟合的问题？</strong></p><ul><li>如果数据中存在噪音，模型有将==噪音==一起过度学习，导致模型失效。</li><li>如果不使用正则化，模型参数学习的较大，导致模型过拟合，过度依赖某些特征，==不具备泛化性==。</li></ul></blockquote><blockquote><p><strong>8. 解决过拟合的方法？</strong></p><ul><li>降低模型复杂度：处理过拟合的第一步就是降低模型复杂度。</li><li>增加数据量：使用更大的数据集训练模型。</li><li>数据增强，对原有样本做变换：比如在 CV 中，对图片进行翻转。</li><li>正则化：<ul><li>L1, L2</li><li>Dropout</li></ul></li><li>早停：当相邻两次结果变化小于一定程度时，就停止训练，防止过度学习。</li><li>重新清洗数据：把明显异常值剔除。</li><li>使用集成学习方法：把多个模型集成在一起，降低单个模型的过拟合风险。</li><li>BatchNorm 批量归一</li></ul></blockquote><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>评估指标：<br><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.bilibili.com/video/BV1oz4y1R71a">【小萌五分钟】机器学习 | 混淆矩阵 Confusion Matrix_bilibili</a><br><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.bilibili.com/video/BV1wz4y197LU">【小萌五分钟】机器学习 | 模型评估: ROC曲线与AUC值_bilibili</a><br><a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/147663370">多分类模型 Accuracy, Precision, Recall 和 F1-score 的超级无敌深入探讨 - 知乎</a><br><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.xuebawang.net/t/47417">「评估」AUC离线好,上线差?试试GAUC</a></p><p>Linux 命令：<br><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.ruanyifeng.com/blog/2018/11/awk.html">awk 入门教程 - 阮一峰的网络日志</a><br><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.runoob.com/linux/linux-comm-awk.html">Linux awk 命令 | 菜鸟教程</a><br><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.runoob.com/linux/linux-comm-tr.html">Linux tr命令 | 菜鸟教程</a></p><p>音乐推荐系统实战：<br><a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/qq_36816848/article/details/108383078">音乐推荐系统-CSDN博客</a><br><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/GoAlers/Music-Top-Recommend">GitHub - GoAlers/Music-Top-Recommend</a></p></div><footer class="post-footer"><div class="reward-container"><div>Buy me a coffee</div><button>赞赏</button><div class="post-reward"><div><img src="/images/wechatpay.jpg" alt="1nnoh 微信"> <span>微信</span></div><div><img src="/images/alipay.png" alt="1nnoh 支付宝"> <span>支付宝</span></div></div></div><div class="post-copyright"><ul><li class="post-copyright-author"><strong>本文作者： </strong>1nnoh</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="https://1nnoh.top/12PWF3V/" title="2.2 逻辑回归-part2">https://1nnoh.top/12PWF3V/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener external nofollow noreferrer" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="post-tags"><a href="/tags/FunRec/" rel="tag"><i class="fa fa-tag"></i> FunRec</a> <a href="/tags/ML/" rel="tag"><i class="fa fa-tag"></i> ML</a></div><div class="post-nav"><div class="post-nav-item"><a href="/3E6EVE1/" rel="prev" title="2.2 逻辑回归-part1"><i class="fa fa-chevron-left"></i> 2.2 逻辑回归-part1</a></div><div class="post-nav-item"><a href="/3W8VFN4/" rel="next" title="可解释机器学习-Task01导论">可解释机器学习-Task01导论 <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments gitalk-container"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2022</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">1nnoh</span></div><div class="wordcount"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i> </span><span title="站点总字数">63k</span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">4:46</span></span></div><div class="busuanzi-count"><span class="post-meta-item" id="busuanzi_container_site_pv"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div><script color="0,0,255" opacity="0.5" zindex="-1" count="99" src="https://lib.baomitu.com/canvas-nest.js/1.0.1/canvas-nest.js"></script><script src="/js/prism/prism.js" async></script><script src="/js/prism/prism.js" async></script></div></footer><div class="toggle sidebar-toggle" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div><div class="sidebar-dimmer"></div><div class="back-to-top" role="button" aria-label="返回顶部"><i class="fa fa-arrow-up fa-lg"></i> <span>0%</span></div><div class="reading-progress-bar"></div><a role="button" class="book-mark-link book-mark-link-fixed"></a> <a href="https://github.com/1nnoh" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener external nofollow noreferrer" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script size="150" alpha="0.26" zindex="-2" src="https://lib.baomitu.com/ribbon.js/1.0.2/ribbon.min.js"></script><script src="https://lib.baomitu.com/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script><script src="https://lib.baomitu.com/medium-zoom/1.0.6/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script><script src="https://lib.baomitu.com/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script><script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="https://lib.baomitu.com/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script><script src="/js/third-party/search/local-search.js"></script><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script><script src="/js/third-party/math/mathjax.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/gitalk/1.8.0/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous"><script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"1nnoh","repo":"1nnoh.github.io","client_id":"19227156b4ef17fefc34","client_secret":"2d052e6865196020dd941e7bacedbb7b85880af7","admin_user":"1nnoh","distraction_free_mode":true,"proxy":"https://frolicking-zabaione-1b2f6e.netlify.app/github_access_token","language":"zh-CN","js":{"url":"https://lib.baomitu.com/gitalk/1.8.0/gitalk.min.js","integrity":"sha256-MVK9MGD/XJaGyIghSVrONSnoXoGh3IFxLw0zfvzpxR4="},"path_md5":"9b917eed73c629f177d095260d5c0438"}</script><script src="/js/third-party/comments/gitalk.js"></script></body></html>