<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222" media="(prefers-color-scheme: light)"><meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0"><link rel="preconnect" href="https://fonts.loli.net" crossorigin><link rel="preconnect" href="https://lib.baomitu.com" crossorigin><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png"><link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Noto+Serif+SC:300,300italic,400,400italic,700,700italic%7CLato:300,300italic,400,400italic,700,700italic%7C'Noto+Sans':300,300italic,400,400italic,700,700italic%7Csans-serif:300,300italic,400,400italic,700,700italic%7C'Noto+Sans+SC':300,300italic,400,400italic,700,700italic%7CRoboto+Serif:300,300italic,400,400italic,700,700italic%7CSource+Code+Pro:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="https://lib.baomitu.com/font-awesome/6.2.0/css/all.min.css" integrity="sha256-AbA177XfpSnFEvgpYu1jMygiLabzPCJCRIBtR5jGc0k=" crossorigin="anonymous"><script class="next-config" data-name="main" type="application/json">{"hostname":"1nnoh.top","root":"/","images":"/images","scheme":"Mist","darkmode":"auto","version":"8.13.2","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"width":269},"copycode":{"enable":false,"style":"flat"},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":{"gitalk":{"order":-1}}},"stickytabs":false,"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script><link rel="stylesheet" href="/js/prism/prism.css"><meta name="description" content="0x00 Abstract 自然语言处理就是研究如何让计算机理解人类语言的一门技术。将计算机不能理解的人类语言编码成可以理解的向量化表示，是 NLP 工作的开始与基础。TF-IDF 是 NLP 入门的基础知识。通过对这种编码方式的学习，可以使我们更加容易理解 NLP 工作的本质。"><meta property="og:type" content="article"><meta property="og:title" content="矢量语义与嵌入之 TF-IDF 检索"><meta property="og:url" content="https://1nnoh.top/280EQA3/index.html"><meta property="og:site_name" content="1nnoh&#39;s Blog"><meta property="og:description" content="0x00 Abstract 自然语言处理就是研究如何让计算机理解人类语言的一门技术。将计算机不能理解的人类语言编码成可以理解的向量化表示，是 NLP 工作的开始与基础。TF-IDF 是 NLP 入门的基础知识。通过对这种编码方式的学习，可以使我们更加容易理解 NLP 工作的本质。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203211003678.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203211033747.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203211047534.png"><meta property="og:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203211101372.png"><meta property="article:published_time" content="2022-03-21T16:16:23.000Z"><meta property="article:modified_time" content="2022-03-21T16:16:23.000Z"><meta property="article:author" content="1nnoh"><meta property="article:tag" content="NLP"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203211003678.png"><link rel="canonical" href="https://1nnoh.top/280EQA3/"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://1nnoh.top/280EQA3/","path":"280EQA3/","title":"矢量语义与嵌入之 TF-IDF 检索"}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>矢量语义与嵌入之 TF-IDF 检索 | 1nnoh's Blog</title><script src="/js/third-party/analytics/baidu-analytics.js"></script><script async src="https://hm.baidu.com/hm.js?b20166297c5501f4ebb46c56425f8cb4"></script><script async defer data-website-id="" src=""></script><script defer data-domain="" src=""></script><link rel="stylesheet" href="/js/prism/prism.css"><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><p class="site-title">1nnoh's Blog</p><i class="logo-line"></i></a></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" maxlength="80" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close" role="button"><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class="search-result-icon"><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#x00-abstract"><span class="nav-text">0x00 Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#x01-tf-idf-%E7%9A%84%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-text">0x01 TF-IDF 的使用场景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#x02-tf-idf-%E7%9A%84%E5%8E%9F%E7%90%86"><span class="nav-text">0x02 TF-IDF 的原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#x03-tf-idf-%E7%9A%84%E5%BA%94%E7%94%A8"><span class="nav-text">0x03 TF-IDF 的应用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#x04-%E5%90%91%E9%87%8F%E5%8C%96%E8%A1%A8%E8%BE%BE"><span class="nav-text">0x04 向量化表达</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#x05-%E8%AF%8D%E8%A2%8B%E6%A8%A1%E5%9E%8B%E4%B8%8E-tf-idf"><span class="nav-text">0x05 词袋模型与 TF-IDF</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%8D%E9%9B%86%E4%B8%8E%E8%AF%8D%E8%A2%8B%E6%A8%A1%E5%9E%8B"><span class="nav-text">词集与词袋模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%8D%E8%A2%8B%E6%A8%A1%E5%9E%8B%E4%B8%8E-tf-idf-%E8%81%94%E5%90%88%E4%BD%BF%E7%94%A8"><span class="nav-text">词袋模型与 TF-IDF 联合使用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#x06-%E6%96%87%E6%9C%AC%E5%90%91%E9%87%8F%E5%8C%96"><span class="nav-text">0x06 文本向量化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#conclusion"><span class="nav-text">Conclusion</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#references"><span class="nav-text">References</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="1nnoh" src="/images/avatar.jpg"><p class="site-author-name" itemprop="name">1nnoh</p><div class="site-description" itemprop="description">如常.</div></div><div class="site-state-wrap site-overview-item animated"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">16</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">7</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">9</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author site-overview-item animated"><span class="links-of-author-item"><a href="https://github.com/1nnoh" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;1nnoh" rel="noopener external nofollow noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:jhhou.cn@gmail.com" title="E-Mail → mailto:jhhou.cn@gmail.com" rel="noopener external nofollow noreferrer" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a></span></div><div class="cc-license site-overview-item animated" itemprop="license"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener external nofollow noreferrer" target="_blank"><img src="https://lib.baomitu.com/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a></div></div></div></div></aside></div><div class="main-inner post posts-expand"><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://1nnoh.top/280EQA3/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="1nnoh"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="1nnoh's Blog"><meta itemprop="description" content="如常."></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="矢量语义与嵌入之 TF-IDF 检索 | 1nnoh's Blog"><meta itemprop="description" content=""></span><header class="post-header"><h1 class="post-title" itemprop="name headline">矢量语义与嵌入之 TF-IDF 检索</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2022-03-22 00:16:23" itemprop="dateCreated datePublished" datetime="2022-03-22T00:16:23+08:00">2022-03-22</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Dive-into-NLP/" itemprop="url" rel="index"><span itemprop="name">Dive into NLP</span></a> </span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv"><span class="post-meta-item-icon"><i class="far fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span id="busuanzi_value_page_pv"></span> </span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>2.9k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>13 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><h2 id="x00-abstract">0x00 Abstract</h2><p>自然语言处理就是研究如何让计算机理解人类语言的一门技术。将计算机不能理解的人类语言编码成可以理解的向量化表示，是 NLP 工作的开始与基础。TF-IDF 是 NLP 入门的基础知识。通过对这种编码方式的学习，可以使我们更加容易理解 NLP 工作的本质。 <span id="more"></span></p><blockquote><p>这块内容第一次学的时候比较难理解，后来看到<a target="_blank" rel="noopener external nofollow noreferrer" href="https://mofanpy.com/tutorials/machine-learning/nlp/intro-search/">莫烦老师</a>讲的才算是彻底明白。补充一下这块内容。</p></blockquote><p>NLP 的首要任务：Vector Semantics and Embedding，也可以说是文本向量化，或着文本特征提取。想要表达的就是，NLP 首先要做的是，将文本语言变成计算机可以理解的语言——向量，否则后面的工作自然是无法开展的。</p><p>在文本向量化的问题中，词袋模型（Bag-of-Words Model）和词嵌入（Word Embedding）是两种最常用的模型。更准确地说，词向量只能表征单个词，如果要表示文本，需要做一些额外的处理。本篇笔记首先学习词袋模型与 TF-IDF。</p><h2 id="x01-tf-idf-的使用场景">0x01 <code>TF-IDF</code> 的使用场景</h2><p>以搜索引擎为例，有了批量性地召回相对合适的内容后，比如我已经从 1 亿个网页中召回了 100 万个，但 100 万对于我来说，已经够让我看上好几年了。怎么能再继续提升一下精确度，找到我更在乎的内容呢？</p><p>所以需要对召回的这 100 万个内容，做一个【问题与内容】的相似度排序，只返回那些头部内容（问题指的是用户搜索的词条，内容就是我们召回的网页）。</p><p>因此简单来说，<code>TF-IDF</code> 要做的就是相似度排序，我们取相似度最高的内容返回给用户。从本质上来说，<code>TF-IDF</code> 是一种 <strong>向量表达</strong> 把语言 <strong>向量化</strong>，将词语，句子，文章转为词向量，句向量，文章向量。因为计算机只能理解数字，所以把我们要 <strong>把计算机不能理解的文本转为向量</strong>。等看完后面的内容就会深刻理解为什么 <code>TF-IDF</code> 是 <strong>向量表达</strong>。</p><h2 id="x02-tf-idf-的原理">0x02 <code>TF-IDF</code> 的原理</h2><p><code>TF</code> ：词频（Term Frequency） <code>IDF</code> ：逆文本频率指数（Inverse Document Frequency）</p><ul><li>词频 <code>TF</code> ：反应文章的 <strong>局部信息</strong>。<ul><li>在一篇文章中，越重要的内容，出现（强调）的次数越多，那么词频 <code>TF</code> 就会越高。所以这些高词频的词，就可以代表这篇文章。</li><li>但伴随而来的问题是，文章中许多的语气词或者“你我他”这种词或者标点符号，同样也会出现很多次，但这些词往往也是高频词，但是没有意义。如何解决这种情况？那就需要 <code>IDF</code>。</li></ul></li><li>逆文本频率指数 <code>IDF</code> ：反应系统的 <strong>全局信息</strong>。<ul><li><code>IDF</code> 可以帮助我们判断词语在系统中的 <strong>区分力</strong> 大小。<ul><li>比如，如果 <strong>每篇文章</strong> 中都有“我”，那么它在所有文章中的 <strong>区分力都不强</strong>。</li><li>如果你搜索的关键词是“莫烦”，<strong>全网都没有几个</strong> 叫“莫烦”的，那么“莫烦” <code>IDF</code> 就会很大，即“莫烦”的 <strong>区分力更强</strong>。</li></ul></li><li>既然 <code>TF</code> 是以单篇文章为中心的局部词信息，但并不知道如果放到全局（所有文章），哪些 <code>TF</code> 高频词是全局垃圾词（中性词），是搜索时没有意义的词； <code>IDF</code> 是统计所有文章的全局词信息，可以分辨 <code>TF</code> 中的哪些高频词是全局垃圾词，但并不知道每个单篇文章中的高频关键词。那么为什么不把两种指标结合，发挥各自的优势？因此通过 <code>TF-IDF</code> 来表达一篇文章。</li></ul></li><li><code>TF-IDF</code> : <code>TF</code> × <code>IDF</code><ul><li>将两种指数相乘，得到 <code>TF-IDF</code> 表达一篇文章。</li><li>降低没有意义的词的重要性，突出文章中真正具有关键意义的内容（词语）。</li></ul></li></ul><p>举个例子：比如有以下三篇文章，我们选取图中的四个词来表达这三篇文章。</p><figure><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203211003678.png" alt="|700"><figcaption aria-hidden="true">|700</figcaption></figure><p>计算出这四个词的 <code>TF</code> 与 <code>IDF</code> 之后，将两者相乘，得到 <code>TF-IDF</code>。</p><p><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203211033747.png"></p><p>通过这些词的分数高低，可以判断每篇文章的关键词是什么。比如文章 1，即使“爱”的词频最高，是文章 1 中出现最多的词，但是通过 <code>IDF</code> 判断得知是全局垃圾词，反而“莫烦”的全局区分力更强（即使词频不高），所以根据综合评分 <code>TF-IDF</code> 得知——在文章 1 中，“莫烦” 的权值更重，更能代表这篇文章。</p><p>至此，我们得到了三篇文章的向量化表示，那么如何在搜索中应用这三个文章向量呢？</p><h2 id="x03-tf-idf-的应用">0x03 <code>TF-IDF</code> 的应用</h2><p><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203211047534.png"></p><p>假设我们搜索“莫烦 Python”，计算机首先通过词表的模式，计算这个搜索问句（“莫烦 Python”）的 <code>TF-IDF</code> 值。然后计算搜索问句与每篇文章的 <code>TF-IDF</code> 值的 <code>cosine</code> 距离。简单来说就是将所有文章，按照词向量的维度放入四维空间（对应四个词），然后将搜索问句向量也放进去，最后查找哪一篇文章离这个搜索问句最近，越近说明相似度越高。由此找到与搜索问句最匹配的文章。图中是用三维空间来说明，一样的意思。</p><p>动手实操一下吧： <a target="_blank" rel="noopener external nofollow noreferrer" href="https://radimrehurek.com/gensim/models/tfidfmodel.html">models.tfidfmodel – TF-IDF model — gensim</a></p><h2 id="x04-向量化表达">0x04 向量化表达</h2><p>向量化是 NLP 工作的基础。将问句，词语，句子或者文章，通过数字的形式投射到空间中，也就是将这些语言转为计算机可以理解的向量，然后按照向量的模式指向空间中的某个位置。</p><p><img data-src="https://inno-figurebed.oss-cn-hangzhou.aliyuncs.com/img/202203211101372.png"></p><p>如图，比如 <code>0,23,116.5,21</code> 就是文章 1 的向量表达，下面是文章 2 与搜索问题的向量表达。所以 <code>TF-IDF</code> 本质上是一种向量表达。NLP 中还有许多其他的向量表达与应用，<code>TF-IDF</code> 是其中一种比较基础且好用的一种方式。</p><p>在实际应用中，一般不存在的词是不放入每条数据的词袋的，通过这样的方式来节约内存。这种技术叫稀疏矩阵（Sparse Matrix）：只存储有内容的值，而忽略无内容的值。因此词袋模型的文本表征，其实是一种稀疏向量表达，因为向量里面的元素大部分都是 0，只有出现在当前文本的词语才有词频的赋值。</p><blockquote><p>拓展： <code>TF-IDF</code> 就是一张将 <code>词语重要程度</code> 转换成 <code>向量</code> 的文档展示方式，那么在这些向量中，必定会有主导型元素，而这些元素其实就是这篇文档中很重要的关键词了。因此除了搜索匹配之外，<code>TF-IDF</code> 还有很多的应用，比如将挑选文档中的关键词（将主导元素提取出来）。 另外，由于 <code>IDF</code> 是所有文档的全局信息，那么带有不同属性的文档集群可能拥有不同性质的 <code>IDF</code> 分布。比如金融领域的 <code>IDF</code> 与生物领域的 <code>IDF</code> ，如果我要搜索金融相关的信息，却是在生物领域的 <code>IDF</code> 下搜索，那么得到的结果必然是不准确的。因此我需要一个带有金融属性的 <code>IDF</code> 表来优化对金融子领域的搜索。这也是 IDF 比较重要的应用方式之一。</p></blockquote><h2 id="x05-词袋模型与-tf-idf">0x05 词袋模型与 <code>TF-IDF</code></h2><p>词袋（BoW）模型是数字文本表示的最简单形式。像单词本身一样，我们可以将一个句子表示为一个词向量包（一个数字串）。初入 NLP 可能会对这些概念产生困惑，比如什么是词袋模型，<code>TF-IDF</code> 就是词袋模型吗，下面来解释一下。</p><h3 id="词集与词袋模型">词集与词袋模型</h3><p>词袋模型将所有词语装进一个袋子里，不考虑其词法和语序的问题，即每个词语都是独立的。这个模型的主要作用也就是对文本做单词切分，有点从一篇文章里提取关键词这种意思，旨在 <strong>用向量来描述文本的主要内容</strong>，其中包含了词集与词袋两种。</p><p><strong>词集模型</strong>：单词构成的集合，集合中每个元素只有一个，即词集中的每个元素为一个单词，词集中的每个单词只出现一次，不重复。</p><p><strong>词袋模型</strong>：在词集的基础上加入了频率这个维度，即统计单词在文档中出现的次数（令牌化和出现频数统计），通常我们在应用中都选用词袋模型。或者说，在词集的基础上，如果一个单词在文档中出现不止一次，统计其出现的次数。说人话就是，将每篇文章看成一袋子词，并忽略每个词出现的顺序。</p><h3 id="词袋模型与-tf-idf-联合使用">词袋模型与 <code>TF-IDF</code> 联合使用</h3><p>词袋创建一组向量，其中包含文档中的单词出现次数，而 <code>TF-IDF</code> 编码可以识别其中每个单词的区分力，然后赋予权重。因此通过词袋模型是一种基础模型， <code>TF-IDF</code> 是一种编码方式，基于词袋模型，我们可以采用 <code>TF-IDF</code> 编码，也可以使用 One-Hot 编码或者其他的编码方式。</p><p>我理解就是，恰好词袋模型实现了词频统计，恰好这正是 <code>TF</code> 要做的事情，所以再加上 <code>IDF</code> 联合起来，基于词袋模型实现了我们要做的 <code>TF-IDF</code> 编码。</p><h2 id="x06-文本向量化">0x06 文本向量化</h2><p>刚入门 NLP 想必会对这些专业名词头晕眼花，下面简单列举一下关系：</p><ul><li>文本向量化（文本表征 Word Representation）<ul><li>词袋模型及其编码方法（BoW）<ul><li>One-Hot 编码</li><li>TF 编码</li><li>TF-IDF 编码</li><li>N-gram 编码</li></ul></li><li>词嵌入模型（Word Embedding）<ul><li>Word2Vec<ul><li>Skip-Gram 模型</li><li>CBOW 模型</li></ul></li><li>GloVe</li></ul></li><li>主题模型（Topic Model）<ul><li>LSA 模型</li><li>PLSA 模型</li><li>LDA 模型</li></ul></li></ul></li></ul><h2 id="conclusion">Conclusion</h2><p>Bag-of-Words Model（BoW）和 <code>TF-IDF</code> 编码都是帮助我们将文本句子转换为向量的技术，是使得机器理解文本的技术。</p><p>但是 BoW 这样的技术会有一些弊端，比如语序关系丢失（忽略上下文），异常依赖于优秀的词汇库，缺乏相似词之间的表达，并且向量稀疏。为了解决这些问题，下一篇笔记学习另一类向量化的方法——Word Embedding 词嵌入。即自然语言中的词语转化为稠密的向量，相似的词会有相似的向量表示，这样的转化方便挖掘文字中词语和句子之间的特征。</p><h2 id="references">References</h2><p>TF-IDF: <a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/weixin_44799217/article/details/116423520">自然语言处理(NLP)之使用 TF-IDF 模型计算文本相似度</a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://mofanpy.com/tutorials/machine-learning/nlp/intro-search/">你天天用的搜索引擎是怎么工作的 - 自然语言处理 | 莫烦 Python</a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://mofanpy.com/tutorials/machine-learning/nlp/tfidf/">统计学让搜索速度起飞 - 自然语言处理 | 莫烦 Python</a></p><p>词袋模型与 TF-IDF: <a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.jianshu.com/p/0422853b57a8">词袋模型与 TF-IDF</a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/fendouaini/article/details/108655680">词袋模型和 TF-IDF</a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/baidu_41797613/article/details/121268152">词袋模型与 TF-IDF 模型</a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.jiqizhixin.com/graph/technologies/87c62b00-48b2-4e2a-8122-9876a3d3e59e">词袋模型 | 机器之心</a></p><p>词袋模型与词嵌入： <a target="_blank" rel="noopener external nofollow noreferrer" href="https://davidchen93.blog.csdn.net/article/details/79993369?spm=1001.2101.3001.6661.1&amp;utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_default&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_default&amp;utm_relevant_index=1">词袋模型和词向量模型概念介绍</a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhuanlan.zhihu.com/p/71065945">从词袋模型 TF-IDF 到词嵌入 Word Embedding</a></p><p>斯坦福经典 NLP 教材： <a target="_blank" rel="noopener external nofollow noreferrer" href="https://web.stanford.edu/~jurafsky/slp3/6.pdf">https://web.stanford.edu/~jurafsky/slp3/6.pdf</a></p></div><footer class="post-footer"><div class="reward-container"><div>Buy me a coffee</div><button>赞赏</button><div class="post-reward"><div><img src="/images/wechatpay.jpg" alt="1nnoh 微信"> <span>微信</span></div><div><img src="/images/alipay.png" alt="1nnoh 支付宝"> <span>支付宝</span></div></div></div><div class="post-copyright"><ul><li class="post-copyright-author"><strong>本文作者： </strong>1nnoh</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="https://1nnoh.top/280EQA3/" title="矢量语义与嵌入之 TF-IDF 检索">https://1nnoh.top/280EQA3/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener external nofollow noreferrer" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="post-tags"><a href="/tags/NLP/" rel="tag"><i class="fa fa-tag"></i> NLP</a></div><div class="post-nav"><div class="post-nav-item"><a href="/2F4301H/" rel="prev" title="爬虫与网络编程基础-Task02：HTTP 协议与 Requests"><i class="fa fa-chevron-left"></i> 爬虫与网络编程基础-Task02：HTTP 协议与 Requests</a></div><div class="post-nav-item"><a href="/CGCSR4/" rel="next" title="阿里灵杰_Task02_词向量介绍与训练">阿里灵杰_Task02_词向量介绍与训练 <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments gitalk-container"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2022</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">1nnoh</span></div><div class="wordcount"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i> </span><span title="站点总字数">54k</span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">4:06</span></span></div><div class="busuanzi-count"><span class="post-meta-item" id="busuanzi_container_site_pv"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div><script color="0,0,255" opacity="0.5" zindex="-1" count="99" src="https://lib.baomitu.com/canvas-nest.js/1.0.1/canvas-nest.js"></script><script src="/js/prism/prism.js" async></script><script src="/js/prism/prism.js" async></script></div></footer><div class="toggle sidebar-toggle" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div><div class="sidebar-dimmer"></div><div class="back-to-top" role="button" aria-label="返回顶部"><i class="fa fa-arrow-up fa-lg"></i> <span>0%</span></div><div class="reading-progress-bar"></div><a role="button" class="book-mark-link book-mark-link-fixed"></a> <a href="https://github.com/1nnoh" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener external nofollow noreferrer" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script size="150" alpha="0.26" zindex="-2" src="https://lib.baomitu.com/ribbon.js/1.0.2/ribbon.min.js"></script><script src="https://lib.baomitu.com/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script><script src="https://lib.baomitu.com/medium-zoom/1.0.6/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script><script src="https://lib.baomitu.com/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script><script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="https://lib.baomitu.com/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script><script src="/js/third-party/search/local-search.js"></script><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script><script src="/js/third-party/math/mathjax.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/gitalk/1.8.0/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous"><script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"1nnoh","repo":"1nnoh.github.io","client_id":"19227156b4ef17fefc34","client_secret":"2d052e6865196020dd941e7bacedbb7b85880af7","admin_user":"1nnoh","distraction_free_mode":true,"proxy":"https://frolicking-zabaione-1b2f6e.netlify.app/github_access_token","language":"zh-CN","js":{"url":"https://lib.baomitu.com/gitalk/1.8.0/gitalk.min.js","integrity":"sha256-MVK9MGD/XJaGyIghSVrONSnoXoGh3IFxLw0zfvzpxR4="},"path_md5":"3440a630824b4ac318fdddc19d677ceb"}</script><script src="/js/third-party/comments/gitalk.js"></script></body></html>